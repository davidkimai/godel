# SPEC_NLP_INTENT.md - Natural Language Intent Parsing for Dash

**Version:** 1.0  
**Date:** 2026-02-01  
**Status:** Draft - Ready for Review  
**Author:** Interview Skill Output

---

## Executive Summary

This specification defines the natural language intent parsing system for Dash, a CLI-first agent orchestration platform. The system enables users to express complex goals in natural language (e.g., `dash "Build me a REST API for user management with auth"`) and automatically transforms these requests into executable task graphs with appropriate agent assignments and quality gates.

**Core Capability:** Convert ambiguous, high-level user intent into structured, actionable task decompositions that leverage Dash's multi-agent architecture.

---

## 1. Problem Statement

### The Challenge
Users think in goals and outcomes, not agent capabilities or task graphs. When a user says "Build me a REST API for user management with auth," they expect Dash to:

1. Understand the goal holistically
2. Break it into logical components (API design, authentication, user models, CRUD operations, tests, documentation)
3. Select appropriate specialized agents for each component
4. Establish quality criteria for each task
5. Orchestrate execution with proper dependencies

### Current Gap
Without structured intent parsing, Dash would require users to manually decompose requests, specify agents, and define quality criteria—defeating the purpose of a natural language interface.

---

## 2. Core Questions & Answers

### Q1: What intent patterns should be supported?

**Answer:** Three primary pattern categories, plus composites:

**Pattern A: Build/Create Intent**
```
dash "Build a [artifact] for [domain] with [requirements]"
dash "Create a [component] that does [functionality]"
dash "Implement [feature] for [system]"
```

**Pattern B: Modify/Extend Intent**
```
dash "Add [feature] to [existing_system]"
dash "Extend [component] to support [capability]"
dash "Refactor [module] for [improvement]"
```

**Pattern C: Operate/Manage Intent**
```
dash "Set up [infrastructure] for [purpose]"
dash "Deploy [application] to [environment]"
dash "Configure [service] with [settings]"
```

**Pattern D: Analyze/Research Intent**
```
dash "Analyze [system] for [issues/patterns]"
dash "Research [topic] and summarize findings"
dash "Audit [component] against [criteria]"
```

**Composite Patterns:** Users frequently combine patterns (e.g., "Build X, then deploy it, then set up monitoring").

---

### Q2: How should ambiguous requests be handled?

**Answer:** Four-tiered disambiguation strategy:

**Tier 1: Contextual Resolution**
- Leverage conversation history and user patterns
- Use user's past successful decompositions as hints
- Apply domain knowledge (e.g., "API" implies REST by default unless GraphQL specified)

**Tier 2: Heuristic Disambiguation**
- Apply common-sense reasoning about typical implementations
- Infer missing details from domain conventions
- Default to industry-standard approaches when ambiguous

**Tier 3: User-Friendly Disambiguation**
- Present top 2-3 interpretations with brief explanations
- Allow selection via numbered choice or natural language refinement
- Remember user preference for future similar requests

**Tier 4: Safe Deferral**
- When ambiguity cannot be resolved safely, ask before proceeding
- Offer "proceed with defaults" option for confident users
- Never make irreversible decisions under ambiguity

---

### Q3: What confidence thresholds apply?

**Answer:** Three threshold levels:

| Confidence Level | Score Range | Action |
|-----------------|-------------|--------|
| **HIGH** | 85-100% | Execute immediately, minimal logging |
| **MEDIUM** | 60-84% | Execute with user notification, log for review |
| **LOW** | 40-59% | Request user confirmation before execution |
| **REJECTED** | < 40% | Return structured clarification request |

**Confidence Factors:**
- Pattern match strength (0-30 points)
- Entity recognition clarity (0-25 points)
- Contextual match with history (0-20 points)
- Ambiguity level (0-15 points)
- User preference alignment (0-10 points)

---

### Q4: How does intent parsing integrate with task decomposition?

**Answer:** Bidirectional integration with clear handoff:

```
┌─────────────────────────────────────────────────────────────┐
│                    INTENT PARSING LAYER                      │
│  ┌─────────────┐    ┌─────────────┐    ┌─────────────┐     │
│  │   Lexicon   │    │  Classifier │    │   Entity    │     │
│  │  Matcher    │───▶│   Router    │───▶│  Extractor  │     │
│  └─────────────┘    └─────────────┘    └─────────────┘     │
│         │                  │                  │             │
│         ▼                  ▼                  ▼             │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              CONFIDENCE SCORER                       │   │
│  │        (Threshold Check: 85/60/40)                   │   │
│  └─────────────────────────────────────────────────────┘   │
│                            │                                │
│                            ▼                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              TASK DECOMPOSITION LAYER                │   │
│  │  ┌─────────────┐    ┌─────────────┐    ┌─────────┐  │   │
│  │  │   Task      │───▶│    Agent    │───▶│ Quality │  │   │
│  │  │  Generator  │    │  Selector   │    │  Gate    │  │   │
│  │  └─────────────┘    └─────────────┘    │  Creator │  │   │
│  └─────────────────────────────────────────────────────┘   │
│                            │                                │
│                            ▼                                │
│  ┌─────────────────────────────────────────────────────┐   │
│  │              EXECUTION ORCHESTRATOR                  │   │
│  └─────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
```

**Integration Points:**
1. **Output:** ParsedIntent → TaskGenerator (structured JSON)
2. **Feedback:** TaskExecution → IntentParser (correction signals)
3. **Context:** Shared UserContext (history, preferences, domain models)

---

### Q5: Error handling for unparseable intents?

**Answer:** Comprehensive error taxonomy with recovery strategies:

| Error Type | Example | Recovery Strategy |
|------------|---------|-------------------|
| **LEXICAL** | Gibberish, typos | Suggest corrections, use fuzzy matching |
| **SEMANTIC** | Contradictory requirements | Highlight conflict, ask for clarification |
| **SCOPE** | Impossible request ("make me a sandwich") | Suggest alternative approach, explain limitations |
| **BOUNDARY** | Request outside Dash capabilities | Provide guidance, suggest external tools |
| **AUTH** | Missing permissions for requested action | Request authorization, explain requirements |

**Error Response Format:**
```json
{
  "error_type": "SCOPE",
  "confidence": 0.15,
  "message": "I understand you're asking for a sandwich, but that's outside my current capabilities.",
  "suggestions": [
    "I can help you find sandwich recipes",
    "I can help you order delivery via integration",
    "Would you like to see what I can actually help with?"
  ],
  "clarification_request": "What type of task would you like help with?"
}
```

---

### Q6: Learning from user corrections?

**Answer:** Multi-level learning system:

**Level 1: Session-Level Learning**
- Track corrections within current session
- Apply to immediately subsequent requests
- Discard at session end

**Level 2: User-Level Learning**
- Store successful corrections in user profile
- Weight by frequency of correction
- Apply to all future sessions for that user

**Level 3: Global Learning (Opt-in)**
- Aggregate anonymized correction patterns
- Improve default heuristics
- Requires explicit user consent

**Learning Trigger Events:**
- User explicitly corrects interpretation
- User provides additional clarification unprompted
- User rejects suggested decomposition
- User manually overrides agent selection

**Learning Data Structure:**
```json
{
  "pattern": "Build * REST API",
  "user_correction": {
    "original_entity": "authentication",
    "corrected_entity": "JWT authentication with refresh tokens",
    "frequency": 3,
    "last_updated": "2026-02-01"
  },
  "confidence_boost": 0.15
}
```

---

## 3. Intent Classification Taxonomy

### 3.1 Primary Categories

```
INTENT_HIERARCHY
├── CREATION
│   ├── BUILD (new artifact from scratch)
│   ├── CREATE (new entity instance)
│   ├── IMPLEMENT (add functionality)
│   └── GENERATE (produce output from inputs)
│
├── MODIFICATION
│   ├── ADD (extend with new capability)
│   ├── MODIFY (change existing behavior)
│   ├── REFACTOR (improve structure, preserve behavior)
│   ├── UPDATE (increment version/feature)
│   └── EXTEND (build upon existing)
│
├── OPERATIONAL
│   ├── DEPLOY (release to environment)
│   ├── CONFIGURE (setup and tune)
│   ├── INSTALL (add to system)
│   ├── START/STOP (lifecycle management)
│   └── MONITOR (observe and report)
│
├── ANALYTICAL
│   ├── ANALYSE (examine for patterns/issues)
│   ├── RESEARCH (investigate and report)
│   ├── AUDIT (check against criteria)
│   ├── DEBUG (diagnose problems)
│   └── PROFILE (measure performance)
│
└── MANAGEMENT
    ├── INTEGRATE (connect systems)
    ├── MIGRATE (move between systems)
    ├── BACKUP (create safety copy)
    ├── RESTORE (recover from backup)
    └── SECURE (harden against threats)
```

### 3.2 Entity Types

| Entity Category | Examples | Extraction Priority |
|----------------|----------|---------------------|
| **ARTIFACT** | API, website, CLI tool, library, service | High |
| **DOMAIN** | user management, e-commerce, analytics | High |
| **REQUIREMENT** | authentication, performance, scalability | High |
| **TECHNOLOGY** | Node.js, PostgreSQL, React, GraphQL | Medium |
| **ACTION** | build, deploy, test, document | High |
| **CONSTRAINT** | fast, secure, scalable, cheap | Medium |
| **SCOPE** | frontend, backend, database, full-stack | High |

### 3.3 Modifier Types

- **Scope Modifiers:** `fully`, `partially`, `just the`, `including`
- **Quality Modifiers:** `production-ready`, `MVP`, `prototype`, `enterprise-grade`
- **Time Modifiers:** `quickly`, `ASAP`, `by Friday`, `iteratively`
- **Complexity Modifiers:** `simple`, `complex`, `bare-bones`, `feature-rich`

---

## 4. Parsing Algorithm Approach

### 4.1 Multi-Stage Pipeline

```
Stage 1: Tokenization & Preprocessing
├── Normalize whitespace and punctuation
├── Expand contractions
├── Detect language (default to English)
└── Handle special characters (URLs, code snippets)

Stage 2: Pattern Matching
├── Apply regex patterns for common structures
├── Match against intent taxonomy
├── Extract explicit entities
└── Calculate pattern confidence

Stage 3: NER (Named Entity Recognition)
├── Identify technology names
├── Identify domain concepts
├── Identify action verbs
└── Identify constraint modifiers

Stage 4: Semantic Analysis
├── Resolve pronoun references
├── Handle implied entities
├── Detect composite intents
└── Identify dependency relationships

Stage 5: Confidence Aggregation
├── Weighted combination of stage scores
├── Apply contextual modifiers
├── Check threshold compliance
└── Generate structured output
```

### 4.2 Pattern Matching Algorithm

**Aho-Corasick for Multi-pattern Matching:**
- Pre-compile intent patterns into deterministic finite automaton
- O(n + m) complexity where n = input length, m = total pattern length
- Supports efficient batch matching against 100+ patterns

**Fallback: N-gram Similarity Scoring**
- When no pattern matches exactly, calculate n-gram similarity
- Use Jaccard similarity with n=3
- Return top 3 candidate matches with scores

### 4.3 Entity Resolution Strategy

**Explicit Resolution:**
- Direct dictionary lookup for known entities
- Case-insensitive matching
- Alias support (e.g., "Postgres" → "postgresql")

**Implicit Resolution:**
- Contextual inference from domain models
- Pattern-based guessing (e.g., "user API" → likely REST)
- User history-based inference

**Ambiguity Resolution:**
- Maintain entity ambiguity list
- Generate disambiguation questions
- Defer to user when >2 plausible interpretations

### 4.4 Composite Intent Detection

**Indicators:**
- Conjunctions: "and", "then", "followed by"
- Sequential markers: "first", "next", "after that"
- Parallel structures: "and", "plus", "as well as"

**Processing:**
1. Split on conjunction markers
2. Parse each sub-intent independently
3. Detect inter-dependencies (e.g., B depends on A)
4. Construct task DAG with proper ordering

---

## 5. Confidence Scoring System

### 5.1 Score Components

| Component | Weight | Description |
|-----------|--------|-------------|
| Pattern Match | 30% | How well input matches known patterns |
| Entity Clarity | 25% | How clearly entities are identified |
| Context Match | 20% | Alignment with user history/preferences |
| Ambiguity Level | 15% | Degree of potential misinterpretation |
| Completeness | 10% | Coverage of required components |

### 5.2 Score Calculation Example

```javascript
function calculateConfidence(parsedIntent) {
  const scores = {
    pattern: calculatePatternScore(parsedIntent.pattern, parsedIntent.input),
    entity: calculateEntityScore(parsedIntent.entities),
    context: calculateContextScore(parsedIntent, userHistory),
    ambiguity: calculateAmbiguityScore(parsedIntent),
    completeness: calculateCompletenessScore(parsedIntent)
  };

  return (
    scores.pattern * 0.30 +
    scores.entity * 0.25 +
    scores.context * 0.20 +
    scores.ambiguity * 0.15 +
    scores.completeness * 0.10
  );
}
```

### 5.3 Threshold Behaviors

**HIGH (85-100%):**
- Execute with minimal overhead
- Log for analytics only
- Auto-proceed with decomposition

**MEDIUM (60-84%):**
- Execute with user notification
- Log for review
- Offer "proceed or refine" choice

**LOW (40-59%):**
- Present interpretation(s) for confirmation
- Request additional input
- Do not auto-proceed

**REJECTED (<40%):**
- Return structured clarification request
- Provide suggestions based on partial understanding
- Never attempt execution

---

## 6. Error Handling Strategy

### 6.1 Error Classification

```
ERROR_TYPES
├── PARSE_ERROR
│   ├── LEXICAL_ERROR (invalid tokens)
│   ├── SYNTAX_ERROR (ungrammatical structure)
│   └── OVERFLOW_ERROR (input too long)
│
├── RECOGNITION_ERROR
│   ├── UNKNOWN_INTENT (no matching category)
│   ├── UNKNOWN_ENTITIES (unrecognized terms)
│   └── CONFLICTING_ENTITIES (contradictory requirements)
│
├── RESOLUTION_ERROR
│   ├── AMBIGUOUS_INPUT (multiple interpretations)
│   ├── INSUFFICIENT_CONTEXT (missing information)
│   └── OUT_OF_SCOPE (beyond platform capabilities)
│
└── SYSTEM_ERROR
    ├── TIMEOUT (processing took too long)
    ├── RESOURCE_EXHAUSTED (memory/CPU limits)
    └── INTEGRATION_ERROR (external service failure)
```

### 6.2 Error Response Protocol

**User-Facing Messages:**
- Be helpful, not technical
- Suggest next steps
- Maintain conversational tone

**System-Facing Data:**
- Structured error codes
- Confidence scores at failure point
- Partial parse results (if any)
- Suggested recovery actions

### 6.3 Recovery Mechanisms

**Automatic Recovery:**
- Fuzzy matching for typos (Levenshtein distance ≤ 2)
- Common mistake patterns ("a" → "an", tense mismatches)
- Abbreviation expansion

**Assisted Recovery:**
- Interactive clarification questions
- Example-based prompting
- Progressive disclosure of options

**Graceful Degradation:**
- Attempt partial parse when full parse fails
- Return "best effort" interpretation with confidence warning
- Offer manual task specification as fallback

---

## 7. Integration Points with Dash Infrastructure

### 7.1 External Interfaces

```
                    ┌─────────────────────────────┐
                    │      CLI ENTRY POINT        │
                    │    dash "natural request"   │
                    └──────────────┬──────────────┘
                                   │
                    ┌──────────────▼──────────────┐
                    │    COMMAND PARSER           │
                    │   (argparse/shellwords)     │
                    └──────────────┬──────────────┘
                                   │
                    ┌──────────────▼──────────────┐
                    │   INTENT PARSER (this spec) │
                    │ ┌─────────────────────────┐ │
                    │ │ NLP Pipeline            │ │
                    │ │ • Tokenization          │ │
                    │ │ • Pattern Matching      │ │
                    │ │ • Entity Recognition    │ │
                    │ │ • Confidence Scoring    │ │
                    │ └─────────────────────────┘ │
                    └──────────────┬──────────────┘
                                   │
         ┌─────────────────────────┼─────────────────────────┐
         │                         │                         │
┌────────▼────────┐    ┌──────────▼──────────┐    ┌─────────▼────────┐
│   TASK          │    │    AGENT            │    │   QUALITY GATE   │
│   GENERATOR     │    │    SELECTOR         │    │   CREATOR        │
│                 │    │                     │    │                  │
│ • Decompose     │    │ • Match tasks to    │    │ • Define pass    │
│   into tasks    │    │   agent capabilities│    │   criteria       │
│ • Order tasks   │    │ • Consider load     │    │ • Specify tests  │
│ • Identify      │    │ • Handle agent      │    │ • Set thresholds │
│   dependencies  │    │   conflicts         │    │                  │
└────────┬────────┘    └──────────┬──────────┘    └─────────┬────────┘
         │                        │                          │
         └────────────────────────┼──────────────────────────┘
                                  │
                    ┌──────────────▼──────────────┐
                    │  EXECUTION ORCHESTRATOR     │
                    │  (existing Dash core)       │
                    └─────────────────────────────┘
```

### 7.2 Data Contracts

**Input Format (CLI to Intent Parser):**
```typescript
interface IntentParseRequest {
  rawInput: string;
  userId: string;
  sessionId: string;
  context?: {
    previousRequests?: string[];
    activeProject?: string;
    userPreferences?: Record<string, unknown>;
  };
}
```

**Output Format (Intent Parser to Task Generator):**
```typescript
interface ParsedIntent {
  primaryCategory: IntentCategory;
  entities: ExtractedEntity[];
  confidence: number; // 0-100
  suggestedTasks: SuggestedTask[];
  qualityGates: QualityGate[];
  ambiguityWarnings: string[];
}

interface SuggestedTask {
  description: string;
  suggestedAgent: string;
  dependencies: string[]; // task IDs
  estimatedComplexity: 'low' | 'medium' | 'high';
  requiredEntities: string[];
}

interface QualityGate {
  taskId: string;
  criteria: GateCriterion[];
  threshold: number;
}
```

### 7.3 Integration with Mission Control

**Convex Database Schema Requirements:**
```typescript
// IntentParseEvents table
interface IntentParseEvent {
  id: string;
  userId: string;
  sessionId: string;
  rawInput: string;
  parsedIntent: ParsedIntent;
  confidence: number;
  executionOutcome: 'success' | 'partial' | 'failed';
  userCorrections?: UserCorrection[];
  timestamp: Date;
}

// UserPreferences table (for learning)
interface UserNLPPreferences {
  userId: string;
  preferredDefaults: Record<string, string>;
  entityAliases: Record<string, string>;
  correctionHistory: UserCorrection[];
  confidenceThreshold: number; // user override
}
```

### 7.4 Agent Selection Integration

**Agent Capability Registry:**
```typescript
interface AgentCapability {
  agentId: string;
  agentName: string;
  capabilities: string[];
  supportedEntities: string[];
  complexityLevels: {
    low: string[];
    medium: string[];
    high: string[];
  };
}

// Used by Agent Selector to match tasks to agents
function selectAgent(task: SuggestedTask): string {
  const capableAgents = registry.filter(a => 
    a.supportedEntities.some(e => task.requiredEntities.includes(e))
  );
  
  // Rank by capability match score, then by current load
  return rankAgents(capableAgents)[0].agentId;
}
```

---

## 8. Edge Cases

### 8.1 Input Variations

| Edge Case | Example | Handling |
|-----------|---------|----------|
| Empty input | `dash ""` | Prompt for input |
| Whitespace only | `dash "   "` | Same as empty |
| Very long input | 1000+ chars | Truncate with warning, attempt parse |
| Multiple sentences | "Build X. Then deploy it." | Detect composite intent |
| Code mixed with text | `dash "Create { name: string }` | Preserve code, parse around it |
| Non-English | `dash "Construire une API"` | Detect language, use appropriate NLP |
| Slang/Informal | `dash "yo build me an api pls"` | Normalize to standard form |

### 8.2 Ambiguity Scenarios

**Scenario 1: Technology Ambiguity**
```
User: "Build me an API"
Interpretation A: REST API (most common)
Interpretation B: GraphQL API (growing popularity)
Interpretation C: gRPC API (performance-focused)
Resolution: Default to REST, offer choice for informed users
```

**Scenario 2: Scope Ambiguity**
```
User: "Add user authentication"
Interpretation A: Add login to existing system
Interpretation B: Create authentication service from scratch
Interpretation C: Add OAuth to frontend only
Resolution: Ask clarifying question about scope
```

**Scenario 3: Dependency Ambiguity**
```
User: "Build API and test it"
Question: Should testing happen after full API or per-endpoint?
Resolution: Default to end-to-end after completion, allow specification
```

### 8.3 Error Recovery Scenarios

**Scenario: Partial Parse Success**
```
Input: "Build me a REST for user management with auth"
Result: "REST" not recognized, but other entities clear
Action: Proceed with confidence penalty, flag for review
```

**Scenario: Complete Parse Failure**
```
Input: "xyz123 abc789"
Result: No recognizable patterns
Action: "I didn't understand that. Could you rephrase?"
```

---

## 9. Technical Constraints

### 9.1 Performance Requirements

| Metric | Target | Measurement |
|--------|--------|-------------|
| Parse Time (p50) | < 100ms | Single intent, no ambiguity |
| Parse Time (p99) | < 500ms | Complex/composite intent |
| Memory Usage | < 50MB | Per parse operation |
| Throughput | 100 req/sec | Concurrent parsing capacity |
| Startup Time | < 1s | Initial pattern compilation |

### 9.2 Scalability Considerations

- **Pattern Set:** 500+ patterns supported without degradation
- **Entity Dictionary:** 10,000+ entities with O(1) lookup
- **Session Context:** 100 previous requests retained per session
- **Learning Storage:** Unlimited per-user corrections

### 9.3 External Dependencies

- **NLP Library:** Pattern-based matching (no heavy ML dependencies)
- **Entity Recognition:** Lightweight dictionary + heuristics
- **Learning Storage:** Convex DB (existing Dash infrastructure)
- **Caching:** In-memory LRU cache for frequent patterns

### 9.4 Constraints

- **No external API calls** during parse (offline operation)
- **Deterministic output** for same input + context
- **Privacy-preserving** (no user data sent externally)
- **Backward compatible** across Dash versions

---

## 10. Trade-offs

### 10.1 Speed vs. Accuracy

| Decision | Trade-off | Rationale |
|----------|-----------|-----------|
| Pattern-based vs. ML | Pattern-based is faster but less flexible | CLI users expect instant response; patterns cover 90% of cases |
| Local processing vs. cloud | Local is faster, cloud could be smarter | Privacy + latency justify local-only |
| Immediate execution vs. confirmation | Execute on HIGH confidence | User convenience for clear requests |

### 10.2 Flexibility vs. Predictability

| Decision | Trade-off | Rationale |
|----------|-----------|-----------|
| Fixed taxonomy vs. extensible | Fixed categories, extensible entities | Users want predictable behavior; entities evolve |
| Strict vs. loose matching | Loose matching, high ambiguity warnings | Better UX than strict rejections |

### 10.3 Learning vs. Privacy

| Decision | Trade-off | Rationale |
|----------|-----------|-----------|
| Global learning | Better defaults, requires opt-in | Privacy-first; aggregate only with consent |
| User-level learning | Personalized, requires storage | Space vs. personalization trade-off |

---

## 11. Future Considerations

### 11.1 Roadmap Items

**Phase 2 (v2.0):**
- Multi-language support (Spanish, French, German)
- Custom pattern definition by users
- Visual intent builder (GUI for complex requests)

**Phase 3 (v3.0):**
- Semantic understanding (lightweight ML integration)
- Voice input support
- Predictive intent suggestions

### 11.2 Extensibility Points

- **Custom Entity Types:** Users can add domain-specific entities
- **Pattern Plugins:** External pattern packages via npm/composer
- **Custom Quality Gates:** User-defined验收 criteria
- **Agent Capability Extensions:** Plugins add new agent types

### 11.3 Scalability Evolution

- **Pattern Compilation:** Pre-compiled patterns for cold starts
- **Distributed Parsing:** Shard by user for massive scale
- **Model Updates:** Hot-reload pattern/entity updates

---

## 12. Concerns & Open Questions

### 12.1 Unresolved Questions

| Question | Impact | Recommended Resolution |
|----------|--------|------------------------|
| How to handle culturally-specific expressions? | Medium | Default to English patterns, build locale packs |
| Should we support intent templates? | Low | Future Phase 2 feature |
| How to handle conflicting user corrections? | Medium | Last-write-wins with frequency weighting |
| Rate limiting for parsing? | Low | 100 req/sec per user seems safe |
| Offline mode with cached patterns? | High | Include offline bundle, update periodically |

### 12.2 Risks

| Risk | Mitigation |
|------|------------|
| Pattern explosion leading to slow parsing | Binary search on patterns, early exit |
| Over-reliance on defaults causing frustration | Clear disambiguation UX |
| Learning system creating bias | Diversity checks, opt-out available |
| Ambiguity causing wrong execution | Low confidence = require confirmation |

### 12.3 Dependencies on Other Teams

| Dependency | Status | Notes |
|------------|--------|-------|
| Convex schema updates | Required | Add intent parsing tables |
| Agent Registry updates | Required | Add capability matching |
| CLI integration | Required | Pass-through implementation |
| UI for disambiguation | Future | Currently CLI-only |

---

## 13. Final Review Summary

### Key Decisions Documented

1. **Three-tier confidence system** (85/60/40) with clear action mappings
2. **Pattern-based parsing** with n-gram fallback (no heavy ML)
3. **Four-stage ambiguity handling** (context → heuristics → user → defer)
4. **Three-level learning system** (session → user → global opt-in)
5. **Composite intent detection** via conjunction analysis
6. **Structured output contract** for downstream integration

### Critical Requirements

- < 500ms parse time for p99
- Offline operation (no external API calls)
- Privacy-preserving (no user data externalized)
- Deterministic output for reproducibility
- Clear error recovery with user guidance

### Success Metrics

| Metric | Target |
|--------|--------|
| Parse success rate | > 95% |
| High confidence rate | > 70% of requests |
| User correction rate | < 10% of requests |
| Parse time (avg) | < 150ms |
| Task decomposition accuracy | > 90% (user approval) |

### Next Steps

1. ✅ Specification complete
2. ⬜ Review with product team
3. ⬜ Technical design review
4. ⬜ Prototype implementation
5. ⬜ User testing with early access
6. ⬜ Iteration based on feedback
7. ⬜ Production release

---

## Appendix A: Example Parsing Flows

### Example 1: Straightforward Request

```
Input: "dash Build a REST API for user management with auth"

Parsed:
├── category: BUILD
├── entities: {
│   artifact: "REST API",
│   domain: "user management",
│   requirement: "auth"
│ }
├── confidence: 92 (HIGH)
├── tasks: [
│   "Design user data model",
│   "Implement authentication flow",
│   "Create CRUD endpoints",
│   "Add input validation",
│   "Write unit tests"
│ ]
├── agents: ["Friday", "Friday", "Friday", "Friday", "Friday"]
└── qualityGates: [
│   { task: "CRUD endpoints", test: "integration tests pass" }
│ ]
```

### Example 2: Ambiguous Request

```
Input: "dash Add search to the API"

Parsed:
├── category: ADD
├── entities: {
│   artifact: "API",  // ambiguous: which API?
│   action: "search"  // ambiguous: full-text? filtered? fuzzy?
│ }
├── confidence: 45 (LOW)
├── ambiguity: [
│   "Which API? (user API, product API, all?)",
│   "What kind of search? (basic, full-text, AI-powered?)"
│ ]
├── clarification: [
│   "Which API should I add search to?",
│   "What type of search do you need?"
│ ]
└── action: Request user clarification
```

---

## Appendix B: Pattern Reference

### Common Patterns (v1.0)

```
BUILD_PATTERNS = [
  "build a {artifact} for {domain}",
  "create a {artifact} for {domain}",
  "implement {feature} for {system}",
  "develop a {artifact} with {requirements}"
]

MODIFY_PATTERNS = [
  "add {feature} to {system}",
  "extend {component} to support {capability}",
  "refactor {module} for {improvement}",
  "update {system} with {changes}"
]

OPERATE_PATTERNS = [
  "deploy {application} to {environment}",
  "set up {infrastructure} for {purpose}",
  "configure {service} with {settings}",
  "start {service}"
]

ANALYZE_PATTERNS = [
  "analyze {system} for {issues}",
  "research {topic}",
  "audit {component} against {criteria}",
  "debug {system}"
]
```

---

**Document Version:** 1.0  
**Last Updated:** 2026-02-01  
**Next Review:** After product team review
