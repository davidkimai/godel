# Godel Production Readiness Document (PRD) v2.0
## Meta-Orchestrator Platform for 10-50+ OpenClaw Sessions

**Version:** 2.0  
**Date:** 2026-02-05  
**Status:** Production Hardening Phase  
**Classification:** Engineering Blueprint - Implementation Ready  

---

## Table of Contents

1. [Executive Summary](#1-executive-summary)
2. [Market Context & Competitive Positioning](#2-market-context--competitive-positioning)
3. [Problem Statement](#3-problem-statement)
4. [Goals & Objectives](#4-goals--objectives)
5. [User Stories](#5-user-stories)
6. [Functional Requirements](#6-functional-requirements)
7. [Non-Functional Requirements](#7-non-functional-requirements)
8. [Security Requirements](#8-security-requirements)
9. [Architecture & Technical Approach](#9-architecture--technical-approach)
10. [API Contract Specifications](#10-api-contract-specifications)
11. [Data Model & Storage](#11-data-model--storage)
12. [Observability & Monitoring](#12-observability--monitoring)
13. [Testing Strategy](#13-testing-strategy)
14. [Deployment & Operations](#14-deployment--operations)
15. [Disaster Recovery](#15-disaster-recovery)
16. [Success Metrics](#16-success-metrics)
17. [Timeline & Milestones](#17-timeline--milestones)
18. [Dependencies & Risks](#18-dependencies--risks)
19. [Open Questions](#19-open-questions)
20. [Appendices](#20-appendices)

---

## 1. Executive Summary

### 1.1 Product Vision

Godel is a **production-grade meta-orchestration control plane** designed to manage 10-50+ concurrent OpenClaw gateway sessions with enterprise reliability, observability, and operational efficiency. Godel operates as the central nervous system for AI agent teams, providing unified task dispatch, priority queue management, session federation, and comprehensive lifecycle orchestration across heterogeneous OpenClaw instances.

### 1.2 Target Market & Use Cases

**Primary Segments:**
- **AI-Native Startups (10-50 engineers):** Companies building with AI-first architecture requiring reliable agent orchestration
- **Enterprise DevOps Teams:** Organizations seeking to standardize AI agent operations across multiple projects
- **Managed Service Providers:** Teams offering AI coding assistance as a service to multiple clients
- **Platform Engineering Teams:** Groups building internal developer platforms with embedded AI capabilities

**Core Use Cases:**
1. **Multi-Project Code Migration:** Orchestrate simultaneous large-scale refactoring across 20+ repositories
2. **Feature Development at Scale:** Deploy 30+ agents to implement features across microservices concurrently
3. **Code Review Automation:** Queue and prioritize AI-powered code reviews with SLA guarantees
4. **Documentation Synchronization:** Maintain consistency across documentation suites using distributed agents
5. **Testing & QA Orchestration:** Run comprehensive test suites with intelligent prioritization and resource allocation

### 1.3 Competitive Positioning

**Market Context (2025-2030):**
- AI Orchestration Market: $11.02B (2025) ‚Üí $30.23B (2030) at 22.3% CAGR
- Agentic AI Market: $7.06B (2025) ‚Üí $93.20B (2032) at 44.6% CAGR
- 62% of organizations anticipate >100% ROI from agentic AI implementation

**Godel Differentiators:**
| Capability | Traditional Orchestrators | AI-Native Platforms | Godel Advantage |
|------------|---------------------------|---------------------|----------------|
| Session-Aware Routing | Basic load balancing | Token-based routing | OpenClaw-native session affinity with priority-safe dispatch |
| Priority Queue Semantics | FIFO/LIFO only | Manual prioritization | Four-tier priority (critical/high/medium/low) with strict ordering |
| Agent Lifecycle | VM/container-based | Ephemeral functions | Full OpenClaw session lifecycle with state preservation |
| Cost Optimization | Reactive scaling | Fixed capacity | Predictive scaling with workload-aware bin packing |
| Multi-Tenancy | Namespace isolation | Basic RBAC | Session-level isolation with resource quotas per tenant |
| Observability | Metrics/logs | Basic tracing | End-to-end correlation across all OpenClaw instances |

### 1.4 Business Outcomes

**Quantified Value Propositions:**
- **Developer Productivity:** 3-5x improvement in code task throughput vs. single-agent workflows
- **Infrastructure Efficiency:** 40-60% better resource utilization through intelligent bin-packing
- **Operational Reliability:** 99.9% task completion rate with automatic retry and dead-letter handling
- **Cost Reduction:** 30-50% lower AI compute costs through optimal session routing and batching

**Validation:** PRD scope is concrete, measurable, and directly aligned to the user objective (10-50+ concurrent OpenClaw operations with production reliability).

---

## 1.5 The Ideal Agent-First Orchestration Platform

### Interview-Driven Design Philosophy

Based on recursive self-interview exploring what would constitute an *ideal* agent-first orchestration platform, the following principles and features define the north star for Godel:

#### The Core Paradigm Shift: From "Tools" to "Teammates"

**Current State (Without Godel):**
- AI agents are "tools" I operate manually
- Context switching between 5+ terminal windows
- I am the bottleneck, constantly checking "did it finish?"
- Every failure requires my immediate attention

**Ideal State (With Godel):**
- Agents are "teammates" that coordinate autonomously
- Single dashboard, unified context, zero switching
- System self-manages, escalates only when truly stuck
- I focus on direction, not execution details

**The Metaphor:**
> "Godel is not a faster horse‚Äîit's a car. You don't manage the engine, transmission, and wheels separately. You say 'take me to San Francisco' and the system figures out the rest."

#### The "Intent-Based" Interface

**Current Friction:**
```bash
# Today's reality (high cognitive load)
godel task create \
  --agent agent-7 \
  --priority high \
  --worktree /path/to/repo \
  --prompt "Implement OAuth2 login with Google provider using Passport.js, 
    ensure CSRF protection, add rate limiting, write tests, 
    update documentation, create migration for user table"
```

**Ideal Experience:**
```bash
# Tomorrow's reality (intent-based)
godel do "Add Google OAuth login with security best practices"

# Or via web UI: type and submit
```

**System Autonomously Determines:**
- Which agents have OAuth/security expertise
- Dependency order (migration ‚Üí backend ‚Üí frontend ‚Üí tests)
- Parallelization opportunities (backend and docs can happen simultaneously)
- Quality gates (security review before merge)
- Rollback strategy if issues detected

#### The Self-Healing Team Architecture

**What Makes It "Agent-First":**

1. **Autonomous Coordination**
   - Agents negotiate task assignments among themselves
   - Load balancing happens organically, not top-down
   - Dead agents are replaced automatically without human intervention

2. **Emergent Intelligence**
   - System learns which agent combinations work best
   - Pattern recognition: "Tasks with 'auth' keyword + Agent-3 = 95% success"
   - Self-optimizing dispatch over time

3. **Collective Problem-Solving**
   - Stuck agent can "ask for help" from peer agents
   - Debugging agents spawned automatically on failure patterns
   - Knowledge sharing: solutions propagate across agent pool

**Concrete Example:**
```
User: "Refactor the payment module to use Stripe"

Godel Orchestrates:
‚îú‚îÄ‚îÄ Agent-A (Architecture): Design new payment flow
‚îú‚îÄ‚îÄ Agent-B (Backend): Implement Stripe API integration
‚îú‚îÄ‚îÄ Agent-C (Frontend): Update checkout components
‚îú‚îÄ‚îÄ Agent-D (Security): Review PCI compliance
‚îú‚îÄ‚îÄ Agent-E (Tests): Write integration tests
‚îî‚îÄ‚îÄ Agent-F (Docs): Update API documentation

Failure Scenario:
‚îî‚îÄ‚îÄ Agent-B encounters OAuth error
    ‚îî‚îÄ‚îÄ Auto-spawns Agent-G (OAuth specialist)
        ‚îî‚îÄ‚îÄ Fixes issue, shares solution with Agent-B
        ‚îî‚îÄ‚îÄ Task continues without human intervention
```

#### The Perfect Day with Ideal Godel

| Time | Activity | System State | Human Experience |
|------|----------|--------------|------------------|
| **8:00 AM** | Morning standup | Dashboard shows overnight progress: 23 tasks completed, 3 pending review | Confidence: "The team worked while I slept" |
| **9:30 AM** | Sprint planning | Natural language input: "Build user profile feature" ‚Üí System generates task breakdown | Agency: "I direct, system executes" |
| **10:00 AM** | Deep work | Agents team in parallel, real-time progress visualization | Flow: "No interruptions, full focus" |
| **12:00 PM** | Issue detected | 1 agent stuck on edge case ‚Üí Auto-escalation to specialist agent ‚Üí Resolved | Trust: "System handles problems gracefully" |
| **2:00 PM** | Review | Side-by-side diffs, batch approvals, one-click merge | Delight: "Quality output, minimal effort" |
| **5:00 PM** | EOD | Summary: 47 tasks, $23 LLM cost, 99.7% success, 0 human interventions | Peace: "Everything just works" |

#### Differentiation: The "Invisible Orchestrator"

| Competitor | Their Approach | Godel's Ideal |
|------------|---------------|--------------|
| **Gas Town** | Terminal-native, manual coordination | Web-first, autonomous coordination |
| **Conductor** | Mac-only, isolated workspaces | Cross-platform, unified team |
| **Loom** | Enterprise server-side | Developer-friendly, open core |
| **CrewAI** | Framework for coding | Runtime for execution |
| **Temporal** | Workflow-as-code | Intent-as-workflow |

**Core Differentiation:**
> "The orchestrator so reliable it disappears. You describe intent, the system handles implementation. Only escalates when human judgment is truly irreplaceable."

#### Anti-Features: The "Don't" List

| Anti-Pattern | Why It Kills Productivity | Godel's Approach |
|--------------|---------------------------|-----------------|
| **Configuration Hell** | 47 YAML files, endless env vars | Sensible defaults, convention over configuration |
| **Opaque Failures** | "Error 500", no context, lost work | Full trace, root cause analysis, automatic retry |
| **Vendor Lock-in** | Only OpenAI, only specific IDE | Multi-provider, open protocols, data export |
| **Surprise Bills** | $500 charge with no warning | Real-time cost tracking, budget alerts, per-task visibility |
| **Context Fragmentation** | Dashboard + terminal + logs + metrics | Single pane of glass, unified context |
| **Manual Coordination** | Human must sequence 20 agents | Autonomous dependency resolution |
| **Static Agents** | Same agent for all tasks | Dynamic specialization, role-based assignment |

#### Magic Features Roadmap

**Phase 1: Intent Dispatch** (Now)
```bash
godel do "Fix the flaky test in auth module"
# System: identifies test, finds agent with context, executes, reports
```

**Phase 2: Self-Healing** (Q2)
```
Agent fails ‚Üí Auto-retry with backoff ‚Üí Escalate to specialist model 
‚Üí Spawn debugging agent ‚Üí Human notification (only if stuck > 10 min)
```

**Phase 3: Knowledge Accumulation** (Q3)
```
System learns: "Agent-7 excels at TypeScript refactors"
Future dispatch: TypeScript tasks ‚Üí Agent-7 (higher probability)
```

**Phase 4: Visual Workflow** (Q4)
- Drag-and-drop pipeline builder
- Real-time team visualization (like Kubernetes dashboard)
- Interactive debugging: pause, inspect, resume agent execution

**Phase 5: Predictive Orchestration** (Future)
```
"Based on your sprint velocity and current queue, 
you'll complete current work by Thursday. 
Shall I start the next epic early?"
```

#### Integration Ecosystem

**Tier 1 (Core):**
- OpenClaw/Pi (native runtime)
- GitHub/GitLab (PRs, issues, Actions)
- Slack/Discord (async notifications)
- VS Code/JetBrains (IDE presence)

**Tier 2 (Enhanced):**
- Linear/Jira (project management sync)
- Figma (design handoff)
- Datadog/Grafana (observability)
- Stripe (billing for SaaS)

**Tier 3 (Extended):**
- Notion/Confluence (documentation)
- Zapier/Make (workflow automation)
- Custom webhooks (enterprise integrations)

#### The Success Metrics That Matter

Beyond technical metrics (latency, throughput), the ideal Godel is measured by:

| Metric | Target | Why It Matters |
|--------|--------|----------------|
| **Cognitive Load** | < 5 min/day managing agents | Human focus on creativity, not coordination |
| **Escalation Rate** | < 2% of tasks need human | System handles routine, humans handle exceptions |
| **Flow State Preservation** | Zero interruptions for routine work | Deep work requires sustained attention |
| **Trust Score** | 99%+ (would you sleep while agents work?) | The ultimate test of reliability |
| **Delight Factor** | NPS > 70 | Users actively recommend to peers |

---

## 1.6 Principles and Trade-offs

### Non-Negotiables

These principles are foundational to Godel's design. Violating them would compromise the product's core value.

| Principle | Description | Why Non-Negotiable |
|-----------|-------------|-------------------|
| **Task Durability** | No task shall be lost silently. Every submitted task must reach terminal state (completed/failed/dead-letter) with audit trail. | Infrastructure that loses work is useless. Trust is permanent. |
| **Session Isolation** | Agent sessions must not interfere with each other. File system, network, and memory isolation are mandatory. | Security and predictability. One misbehaving agent cannot corrupt others. |
| **Observability** | Every operation must be observable: logs, metrics, traces. "Black box" execution is unacceptable. | Debugging distributed systems requires full visibility. No excuses. |
| **Graceful Degradation** | System must degrade gracefully under load, never crash or lose data. Backpressure > overload. | Production systems face chaos. Resilience is not optional. |

### Trade-off Matrix

Explicit decisions about what we optimize for and what we sacrifice:

| Priority | Optimize For | Sacrifice | Mitigation |
|----------|--------------|-----------|------------|
| 1 | Reliability (99.9% uptime) | Latency (tasks may queue) | Priority lanes, fast-path for critical tasks |
| 2 | Cost Efficiency | Implementation Complexity | Clear documentation, battle-tested patterns |
| 3 | Developer Experience | Flexibility | Opinionated defaults with escape hatches |
| 4 | Observability | Performance Overhead | Sampling, async exporters, efficient encoding |
| 5 | Multi-Tenancy | Max Resource Utilization | Over-provisioning headroom, auto-scaling |

### Decision Framework

When faced with architectural decisions, use this priority order:
1. Does it compromise task durability? **REJECT**
2. Does it improve reliability without breaking durability? **ACCEPT**
3. Does it improve cost/UX/observability within reliability constraints? **ACCEPT**
4. Does it reduce cost at expense of reliability? **REJECT**

---

## 2. Market Context & Competitive Positioning

### 2.1 Competitive Landscape Analysis

#### 2.1.1 Traditional Workflow Orchestrators

**AWS Step Functions**
- **Strengths:** Deep AWS integration, visual workflow design, state machine semantics
- **Limitations:** AWS-only, limited AI agent awareness, no session persistence, expensive at scale
- **Pricing:** $0.025 per 1,000 state transitions
- **Gap for Godel:** No native understanding of OpenClaw session lifecycle, no priority queue semantics

**Temporal.io**
- **Strengths:** Durable execution, strong consistency, multi-language SDKs
- **Limitations:** General-purpose (not AI-optimized), complex setup, requires workflow code changes
- **Pricing:** $0.000001 per action (cloud) or self-hosted
- **Gap for Godel:** No built-in agent-specific routing, no session affinity for AI coding agents

**Cadence (Uber)**
- **Strengths:** Battle-tested at scale, open-source, durable execution
- **Limitations:** Heavy infrastructure requirements, steep learning curve
- **Pricing:** Self-hosted only
- **Gap for Godel:** Not designed for AI agent workloads, no awareness of LLM context windows

**Nomad + Kubernetes Jobs**
- **Strengths:** Container-native, flexible scheduling, mature ecosystem
- **Limitations:** Treats agents as stateless containers, no session persistence, no priority queues
- **Pricing:** Infrastructure cost only
- **Gap for Godel:** No understanding of OpenClaw protocol, no session-level management

#### 2.1.2 AI-Native Orchestration Platforms

**LangGraph (LangChain)**
- **Strengths:** Graph-based agent workflows, LangChain ecosystem integration
- **Limitations:** Python-only, focused on LLM chains not coding agents, no session persistence
- **Pricing:** Open source + LangSmith cloud
- **Gap for Godel:** No OpenClaw integration, designed for conversational agents not coding

**CrewAI**
- **Strengths:** Multi-agent collaboration, role-based agents
- **Limitations:** Early stage, limited scalability, no production-grade queue management
- **Pricing:** Open source
- **Gap for Godel:** Not designed for 10-50 concurrent sessions, no federation capabilities

**AutoGPT / AgentGPT**
- **Strengths:** Autonomous agent loops, broad capability
- **Limitations:** Unreliable for production, no orchestration layer, no priority management
- **Pricing:** Open source (API costs only)
- **Gap for Godel:** Godel provides the production orchestration AutoGPT lacks

**Danswer**
- **Strengths:** Enterprise search with AI, document Q&A
- **Limitations:** Focused on search/retrieval, not general agent orchestration
- **Pricing:** Open source + enterprise license
- **Gap for Godel:** Different problem domain (RAG vs. coding agent orchestration)

### 2.2 Feature Comparison Matrix

| Feature | Godel | Temporal | AWS Step Functions | LangGraph | Kubernetes Jobs |
|---------|------|----------|-------------------|-----------|-----------------|
| Priority Queues (4-tier) | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| Session Affinity | ‚úÖ | ‚ö†Ô∏è | ‚ùå | ‚ùå | ‚ùå |
| OpenClaw Native | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| Dead Letter Queue | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ‚ùå | ‚ùå |
| Auto-Retry with Backoff | ‚úÖ | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ‚ùå |
| Multi-Instance Federation | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| WebSocket Event Streaming | ‚úÖ | ‚ùå | ‚ùå | ‚ö†Ô∏è | ‚ùå |
| Cost-Aware Routing | ‚úÖ | ‚ùå | ‚ùå | ‚ùå | ‚ùå |
| Session State Persistence | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚ùå |
| Horizontal Scaling (10-50+) | ‚úÖ | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ‚úÖ |
| Multi-Tenancy | ‚úÖ | ‚úÖ | ‚úÖ | ‚ùå | ‚úÖ |
| API + Dashboard | ‚úÖ | ‚úÖ | ‚úÖ | ‚ö†Ô∏è | ‚ö†Ô∏è |

*Legend: ‚úÖ Full Support, ‚ö†Ô∏è Partial/Limited, ‚ùå Not Available*

### 2.3 Pricing Strategy Implications

**Market Pricing Benchmarks:**
- AWS Step Functions: $25 per million transitions
- Temporal Cloud: ~$1 per million actions
- Self-hosted orchestrators: Infrastructure cost + operational overhead

**Godel Value Proposition:**
Godel operates as a control plane overlay‚Äîcustomers bring their own OpenClaw gateways and infrastructure. The value is in:
1. **Operational efficiency:** Reduced engineering time managing agent fleets
2. **Resource optimization:** Better utilization of existing OpenClaw capacity
3. **Reliability:** Reduced failed tasks and manual intervention

**Recommended Pricing Model:**
- **Open Source Core:** Full functionality, self-hosted
- **Enterprise Add-ons:** Advanced observability, multi-region federation, support SLA
- **Managed Service (Future):** Hosted Godel control plane with usage-based pricing

---

### 2.4 Competitor Feature Adaptation Matrix

**Features Adapted from Competitors:**

| Feature | Source | Adaptation Notes | Godel Enhancement |
|---------|--------|------------------|------------------|
| Git Worktree Isolation | Gas Town Hooks, Conductor | Extend with dependency sharing | Automated cleanup, shared caches |
| Ephemeral Workers | Gas Town Polecats | Add to task queue system | Pool-based pre-warming |
| Multi-Model Routing | Pi | Integrate Pi as primitive | Cost-aware routing, fallback chains |
| Session Tree Navigation | Pi | Dashboard + CLI support | Visual tree, branch management |
| Todo Tracking | Pi, Loom | Tool-based integration | Persistent dashboard panel |
| Merge Queue | Gas Town Refinery | CI/CD integration | Quality gates, auto-rollback |
| Agent Roles | Gas Town 7 Roles | Configurable role system | Custom role definitions |
| Feature Flags | Loom | Runtime toggle system | A/B testing, kill switches |
| Server-Side Proxy | Loom | Security layer | Multi-tenant isolation |
| Remote Execution | Loom Weaver | K8s/Firecracker backend | Ephemeral sandboxes |
| Diff Viewer | Conductor | Web-based viewer | Hunk-level accept/reject |
| Session Persistence | Gas Town Hooks | Checkpoint system | Migration, archival |

**Godel Differentiation Strategy:**
1. **Integration Depth:** While competitors offer isolated features, Godel provides unified orchestration across all capabilities
2. **OpenClaw Native:** Deep integration with OpenClaw/Pi ecosystem vs. generic implementations
3. **Enterprise Ready:** Security, multi-tenancy, and compliance built-in from the start
4. **Observability:** End-to-end tracing across all agent interactions

---

## 3. Problem Statement

### 3.1 Current State Challenges

Godel currently contains the right building blocks (queueing, routing, API, OpenClaw integration, scaling modules) but has reliability and contract-consistency gaps that create deployment risk under concurrency:

**Critical Gaps Identified:**

1. **Queue Correctness Defects**
   - Priority inversion possible in dequeue operations
   - Queue state drift between priority sets and pending list
   - Load accounting inaccuracies during retry scenarios
   - Impact: Critical tasks may be delayed, resource allocation becomes unpredictable

2. **API Contract Drift**
   - Inconsistent `/api` vs `/api/v1` path handling
   - WebSocket path mismatches between dashboard and server
   - Health endpoint registration producing incorrect paths (`/health/health`)
   - Impact: Client breakage, false negatives in health checks

3. **Authentication Weaknesses**
   - JWT tokens decoded without signature verification
   - Timing attack vulnerabilities in token comparison
   - Public route matching bypassable via querystrings
   - Impact: Security vulnerabilities, unauthorized access possible

4. **Adapter Robustness**
   - Runtime crashes during session teardown
   - Partial failure handling gaps in dispose paths
   - Status extraction inconsistencies between OpenClaw versions
   - Impact: Process instability, orphaned sessions

5. **Integration Test Reliability**
   - Configuration defaults causing false negatives
   - Environment-specific failures masking real defects
   - Unclear distinction between infra-missing vs logic failures
   - Impact: Low confidence in test results, deployment hesitation

### 3.2 Production Readiness Requirements

Without hardening queue semantics, auth validation, API compatibility, observability, and test gating, production usage can produce:
- **Silent failure modes:** Tasks lost without notification
- **False positives:** Health checks passing while system is degraded
- **Cascading failures:** One session failure affecting others
- **Operational blindness:** Lack of visibility into 10-50 session states

### 3.3 Risk Assessment

| Risk Category | Severity | Likelihood | Impact | Mitigation Priority |
|--------------|----------|------------|--------|---------------------|
| Queue data loss | Critical | Medium | Task loss, SLA breach | P0 |
| Security bypass | Critical | Low | Unauthorized access | P0 |
| API contract breakage | High | High | Client incompatibility | P0 |
| Adapter crashes | High | Medium | Session instability | P0 |
| Test false negatives | Medium | High | Deployment delays | P1 |
| Performance degradation | Medium | Medium | Poor user experience | P1 |
| Observability gaps | Medium | Medium | Incident response delay | P1 |

---

## 4. Goals & Objectives

### 4.1 Primary Goals

**Goal 1: Reliable Concurrency at Scale**
- Make Godel reliably orchestrate 10-50+ concurrent OpenClaw sessions with deterministic queue and lifecycle behavior
- Success Criteria: Zero task loss under normal operations, <0.1% task loss during degraded conditions

**Goal 2: Stable API Contract**
- Establish a stable and secure API contract for CLI, UI, and integrations
- Success Criteria: 100% backward compatibility within major version, documented deprecation policy

**Goal 3: Defensive Verification Gates**
- Define and enforce verification gates that detect regressions before deployment
- Success Criteria: 100% of releases pass all gates, <5% false positive rate in CI

### 4.2 Secondary Goals

**Goal 4: Operational Excellence**
- Provide comprehensive observability for multi-session operations
- Success Criteria: <30 second mean time to detect (MTTD), <5 minute mean time to resolve (MTTR)

**Goal 5: Developer Experience**
- Enable local development and testing with minimal setup
- Success Criteria: New developer productive in <15 minutes, tests pass locally without external dependencies

**Goal 6: Cost Efficiency**
- Optimize resource utilization across OpenClaw instance pools
- Success Criteria: >70% average instance utilization, <20% over-provisioning

### 4.3 Stretch Goals

**Goal 7: Federation Architecture**
- Support 100+ OpenClaw instances across multiple regions/zones
- Success Criteria: Cross-region routing with <100ms added latency

**Goal 8: Self-Healing Operations**
- Automatic recovery from common failure modes without human intervention
- Success Criteria: >95% of failures self-resolved within 5 minutes

---

## 4.5 Developer Journey Map

### Emotional Journey Through Godel Adoption

| Phase | Emotional State | Touchpoints | Success Metrics |
|-------|-----------------|-------------|-----------------|
| **Discovery** | Curiosity | GitHub README, docs landing, Hacker News | Time to first read < 5 min |
| **Installation** | Anxiety ‚Üí Relief | `npm install -g godel`, `godel onboard` | Install success rate > 95% |
| **First Task** | Apprehension ‚Üí Surprise | CLI submission, dashboard loading | First task completes < 30s |
| **Multi-Agent** | Confidence ‚Üí Delight | 10+ agents running, all succeed | Zero manual intervention |
| **Production** | Trust | 24/7 operation, alerts, runbooks | MTTR < 5 min, MTBF > 7 days |
| **Advocacy** | Enthusiasm | Sharing on Twitter, contributing | NPS > 50 |

### Key "Aha" Moments

1. **The Team:** "I submitted 20 tasks, went to get coffee, came back to all completed"
2. **The Recovery:** "Agent crashed but task resumed from checkpoint automatically"
3. **The Visibility:** "I can see exactly what every agent is doing in real-time"
4. **The Savings:** "My LLM costs dropped 40% with smart routing"

### Pain Points to Address

| Pain Point | Current State (Without Godel) | Future State (With Godel) |
|------------|------------------------------|--------------------------|
| Context Switching | 5+ terminal windows, lost track | Single dashboard, unified view |
| Task Orphans | "Did that agent finish?" | Clear status, automatic retry |
| Merge Conflicts | Manual resolution, 30 min each | Automated merge queue, conflict detection |
| Cost Surprises | Monthly bill shock | Real-time cost tracking, alerts |
| Debug Black Box | "It just failed, no idea why" | Full traces, logs, replay capability |

---

## 5. User Stories

### US-001: Priority-Safe Task Dispatch
**Description:** As a platform operator, I want queue dispatch to respect priority and preserve queue consistency so that critical work executes first and no tasks are lost.

**Acceptance Criteria:**
- [x] Queue dequeue selects tasks from priority structures in `critical > high > medium > low` order
- [x] Retry, scheduled promotion, dead-letter replay, and cancel paths keep queue structures in sync
- [x] Queue depth reflects actual priority queue contents
- [x] Unit tests cover priority dequeue and queue depth behavior
- [x] Typecheck passes

**Technical Implementation:**
- Redis sorted sets for priority ordering (ZADD/ZRANGEBYSCORE)
- Atomic Lua scripts for dequeue operations
- Load adjustment tracking per agent

**API Endpoints:**
- `POST /api/v1/tasks` - Task enqueue with priority
- `GET /api/v1/queue/depth` - Queue depth by priority

**Database Schema:**
- `tasks` table: id, priority, status, assigned_agent, created_at, updated_at
- `agent_load` table: agent_id, current_load, max_capacity

**Priority:** 1 (Critical)  
**Status:** ‚úÖ Implemented  
**Notes:** Implemented in current cycle in `src/queue/task-queue.ts` with comprehensive test coverage

---

### US-002: Correct Retry Load Accounting
**Description:** As an operator, I want agent load counters to be accurate on failures so that schedulers do not over/under-assign work.

**Acceptance Criteria:**
- [x] Failed task retries decrement load for the prior assignee before reassignment
- [x] Agent heartbeat/status reflects corrected load
- [x] Regression tests validate expected transitions
- [x] Typecheck passes

**Technical Implementation:**
- Preserve `previousAssignee` in fail path
- Atomic decrement on retry initiation
- Load validation in heartbeat responses

**API Endpoints:**
- `POST /api/v1/tasks/:id/retry` - Manual retry with load adjustment
- `GET /api/v1/agents/:id/status` - Current load and capacity

**Priority:** 1 (Critical)  
**Status:** ‚úÖ Implemented  
**Notes:** Implemented by preserving `previousAssignee` in fail path with atomic load adjustment

---

### US-003: Hardened JWT Validation
**Description:** As a security owner, I want bearer tokens to be cryptographically validated so that forged tokens are rejected.

**Acceptance Criteria:**
- [x] JWT signature is validated (HS256) with timing-safe compare
- [x] Optional issuer and audience validation supported
- [x] Expiration (`exp`) and not-before (`nbf`) checks remain enforced
- [x] Public route matching is query-safe and non-bypassable
- [x] Typecheck passes

**Technical Implementation:**
- `jsonwebtoken` library with `algorithms: ['HS256']` constraint
- `crypto.timingSafeEqual` for signature verification
- Route matching using pathname only (ignoring querystring)

**Security Considerations:**
- JWT secrets minimum 256 bits
- Token lifetime maximum 24 hours
- Refresh token rotation on every use

**Priority:** 1 (Critical)  
**Status:** ‚úÖ Implemented  
**Notes:** Implemented in `src/api/middleware/auth-fastify.ts` with timing-safe operations

---

### US-004: Health Endpoint Correctness
**Description:** As an SRE, I want health/readiness/liveness endpoints to resolve at expected paths so probes and orchestrators behave correctly.

**Acceptance Criteria:**
- [ ] Health plugin routes map correctly under registered prefixes
- [ ] `/health`, `/health/live`, `/health/ready` are reachable as intended
- [ ] API-prefixed health aliases exist if compatibility mode is enabled
- [ ] Real dependency probes (DB, Redis, OpenClaw) integrated
- [ ] Typecheck passes

**Technical Implementation:**
- Fastify health plugin with prefix-safe route registration
- Dependency health checks with configurable timeouts
- Response format: `{ "status": "healthy|degraded|unhealthy", "checks": {...}, "timestamp": "..." }`

**Health Check Levels:**
- **Liveness:** Process is running (`/health/live`)
- **Readiness:** Can accept traffic (`/health/ready`)
- **Deep Health:** All dependencies healthy (`/health`)

**Priority:** 1 (Critical)  
**Status:** ‚ö†Ô∏è Partial  
**Notes:** Route path corrections implemented in `src/api/health.ts`, real dependency probes pending

---

### US-005: API Contract Compatibility
**Description:** As a frontend and SDK consumer, I want consistent `/api` and `/api/v1` compatibility so clients do not break during migration.

**Acceptance Criteria:**
- [x] Core route groups are available under both `/api/v1/*` and `/api/*`
- [ ] OpenAPI JSON available on both versioned and compatibility endpoints
- [ ] Metrics route module and collector routes are non-conflicting
- [ ] Deprecation headers on `/api/*` routes with sunset date
- [ ] Typecheck passes

**Technical Implementation:**
- Dual route registration in Fastify
- Route aliases with 301 redirects for GET requests
- Deprecation headers: `Deprecation: true`, `Sunset: <date>`

**Migration Path:**
- Phase 1 (Now): Both paths active, `/api` marked deprecated
- Phase 2 (3 months): `/api` returns 301 to `/api/v1`
- Phase 3 (6 months): `/api` removed

**Priority:** 1 (Critical)  
**Status:** ‚ö†Ô∏è Partial  
**Notes:** Implemented in `src/api/fastify-server.ts`, OpenAPI and deprecation headers pending

---

### US-006: WebSocket Contract Alignment
**Description:** As a dashboard user, I want realtime connections to use the correct WS path by default so live updates work without manual overrides.

**Acceptance Criteria:**
- [x] Dashboard WS default path aligns with running server path (`/events`)
- [x] Integration test defaults match WS endpoint conventions
- [x] Automatic reconnection with exponential backoff
- [x] Heartbeat/ping-pong for connection health
- [x] Typecheck passes

**Technical Implementation:**
- Default WebSocket URL: `ws://localhost:7373/events`
- Reconnection: exponential backoff (1s, 2s, 4s, 8s, max 30s)
- Heartbeat interval: 30 seconds

**Event Types:**
- `task.created`, `task.assigned`, `task.completed`, `task.failed`
- `agent.connected`, `agent.disconnected`, `agent.status`
- `session.opened`, `session.closed`, `session.error`

**Priority:** 1 (Critical)  
**Status:** ‚úÖ Implemented  
**Notes:** Updated defaults to `/events` in `src/dashboard/ui/src/services/websocket.ts`

---

### US-007: OpenClaw Adapter Robustness
**Description:** As an orchestration service, I want adapter cleanup and status retrieval to be resilient so failed session teardown does not crash the process.

**Acceptance Criteria:**
- [x] Adapter kill flow handles undefined/error envelopes safely
- [x] Cleanup tolerates bus unsubscribe shape differences
- [x] Status extraction supports top-level and metadata fields
- [x] Dispose path handles partial failures and continues cleanup
- [x] Adapter test suite passes
- [x] Typecheck passes

**Technical Implementation:**
- Defensive null checks on all kill responses
- Try-catch wrappers around cleanup operations
- Graceful degradation when partial state unavailable

**Error Handling:**
- Level 1: Retry operation (3 attempts with backoff)
- Level 2: Mark session for cleanup, continue
- Level 3: Alert operator, log for manual intervention

**Priority:** 1 (Critical)  
**Status:** ‚úÖ Implemented  
**Notes:** Implemented in `src/integrations/openclaw/adapter.ts` with comprehensive error handling

---

### US-008: Integration Test Baseline Reliability
**Description:** As a developer, I want sensible integration defaults so local and CI runs fail for real defects, not obvious environment mismatch.

**Acceptance Criteria:**
- [x] DB connection defaults align to standard test credentials
- [x] WS defaults align with server runtime defaults
- [x] Tests clearly distinguish infra-missing vs logic failures
- [x] Environment-based test gating implemented
- [x] Mock-based fallbacks for hermetic tests
- [x] Typecheck passes

**Test Categories:**
- **Unit Tests:** Always run, no external dependencies
- **Integration-Mocked:** Run with mock services
- **Integration-Live:** Gated behind `RUN_LIVE_INTEGRATION_TESTS=true`
- **E2E:** Gated behind `RUN_E2E_TESTS=true`

**Priority:** 2 (High)  
**Status:** ‚úÖ Implemented  
**Notes:** Defaults updated in `tests/integration/api.test.ts` and `tests/integration/config.ts`

---

### US-009: OpenClaw Instance Federation Design
**Description:** As a platform architect, I want an explicit federation model for 10-50 OpenClaw gateways so scaling is deliberate and safe.

**Acceptance Criteria:**
- [ ] Instance registry schema supports health/load/capabilities/region
- [ ] Routing policy supports tenant affinity, session affinity, and failover
- [ ] Backpressure and max-concurrency policy documented and enforceable
- [ ] Auto-scaling triggers defined for instance pool size
- [ ] Health check protocol between Godel and OpenClaw instances
- [ ] Non-goals and staged rollout plan documented

**Technical Implementation:**
- Registry table: instance_id, endpoint, region, capabilities, health_status, current_load, max_capacity, last_heartbeat
- Routing algorithms: least-loaded, round-robin, session-affinity, capability-match
- Backpressure: Reject new sessions when capacity > 90%

**Federation Topology:**
```
Godel Control Plane
    ‚îú‚îÄ‚îÄ OpenClaw Pool A (Region: us-east, Capacity: 20 instances)
    ‚îú‚îÄ‚îÄ OpenClaw Pool B (Region: us-west, Capacity: 15 instances)
    ‚îî‚îÄ‚îÄ OpenClaw Pool C (Region: eu-west, Capacity: 15 instances)
```

**Priority:** 2 (High)  
**Status:** üìã Design Phase  
**Notes:** Design-level story; implementation starts after P0 hardening complete

---

### US-010: Production Verification Gates
**Description:** As a release manager, I want strict release gates so production deploys are prevented on false-positive test outcomes.

**Acceptance Criteria:**
- [x] Mandatory gates: typecheck, critical unit suites, adapter suite, smoke API checks
- [ ] Load gate profile includes 10, 25, 50 OpenClaw-session equivalents
- [ ] Runbook includes rollback criteria and canary thresholds
- [ ] Automated canary analysis with error rate/latency thresholds
- [ ] Gate failures are blocking for release

**Release Gate Stages:**
1. **Pre-Build:** Lint, typecheck, dependency audit
2. **Unit Tests:** Core modules, queue, auth, adapter
3. **Integration:** Mock and live (if environment available)
4. **Load Test:** 10/25/50 session profiles
5. **Security Scan:** Dependency vulnerabilities, secret detection
6. **Canary:** 5% traffic, 30-minute observation

**Priority:** 1 (Critical)  
**Status:** ‚ö†Ô∏è Partial  
**Notes:** Basic gates implemented, load testing and canary analysis pending

---

### US-011: OpenClaw Daemon Operational Startup
**Description:** As an operator, I want Godel to recover from missing local gateway processes by starting OpenClaw daemon commands automatically (when enabled) so orchestration remains operational.

**Acceptance Criteria:**
- [x] Godel supports configurable daemon start command override
- [x] Godel probes common command variants (`openclaws`, `openclaw`, `openclawd`) when override is not provided
- [x] Startup retry/probe windows are configurable via OpenClaw config/env
- [ ] Graceful degradation when daemon start fails (queue tasks for later)
- [ ] Live integration test validates auto-start behavior against a real gateway lifecycle

**Configuration:**
```yaml
openclaw:
  daemon:
    enabled: true
    command: "openclaw gateway start"  # Override
    probe_interval: 5000ms
    max_retries: 10
    fallback_queue: true  # Queue tasks if no gateway available
```

**Startup Sequence:**
1. Check for existing gateway (health probe)
2. If not found, attempt daemon start
3. Retry probe with backoff
4. If max retries exceeded, enter degraded mode

**Priority:** 1 (Critical)  
**Status:** ‚ö†Ô∏è Partial  
**Notes:** Implemented in `src/core/openclaw.ts`, live integration validation remains environment-dependent

---

### US-012: Multi-Tenant Isolation
**Description:** As an enterprise customer, I want strict tenant isolation so that users from different organizations cannot access each other's data or sessions.

**Acceptance Criteria:**
- [ ] Tenant context propagation through all request paths
- [ ] Database row-level security policies per tenant
- [ ] Redis key namespacing by tenant
- [ ] Session-to-tenant binding with validation
- [ ] Admin APIs for tenant management

**Technical Implementation:**
- JWT claim: `tenant_id`
- Database: RLS policies on all tenant-scoped tables
- Redis: Key prefix `{tenant_id}:`
- API: Tenant validation middleware

**Priority:** 2 (High)  
**Status:** üìã Backlog  
**Notes:** Required for enterprise adoption, depends on federation architecture

---

### US-013: Cost Allocation & Billing
**Description:** As a finance operator, I want detailed usage tracking per tenant/project so that costs can be allocated accurately.

**Acceptance Criteria:**
- [ ] Token usage tracking per session
- [ ] Compute time attribution per task
- [ ] Storage usage per tenant
- [ ] Exportable billing reports
- [ ] Alerting for budget thresholds

**Metrics to Track:**
- LLM tokens (input/output) per session
- Session duration and active time
- Queue wait time per priority level
- Storage: events, logs, artifacts

**Priority:** 3 (Medium)  
**Status:** üìã Backlog  
**Notes:** Required for managed service offering

---

### US-014: Git Worktree-Based Session Isolation
**Description:** As a developer, I want each agent session to operate in an isolated git worktree so that concurrent work on different branches doesn't conflict.

**Acceptance Criteria:**
- [ ] Automatic git worktree creation per session
- [ ] Worktree naming convention: `<repo>-godel-<session-id>`
- [ ] Shared dependencies (node_modules, .venv) via symlinks or shared paths
- [ ] Automatic cleanup of worktrees on session completion
- [ ] Worktree state persistence across session restarts
- [ ] Dashboard view of active worktrees per repository

**Technical Implementation:**
- Git worktree add/remove commands
- Shared dependency detection and linking
- Cleanup policies (immediate, on-success, delayed)

**Inspired By:** Gas Town "Hooks" concept, Conductor isolation model

**Priority:** 2 (High)  
**Status:** üìã Backlog  
**Notes:** Critical for supporting multiple parallel feature branches

---

### US-015: Ephemeral Worker Team ("Polecats")
**Description:** As a platform operator, I want to spin up ephemeral worker agents that complete a single task and terminate, enabling efficient work-swarming patterns.

**Acceptance Criteria:**
- [ ] One-shot task execution with automatic session cleanup
- [ ] Configurable worker lifespan (task-bound, time-bound, or manual)
- [ ] Worker pools with pre-warmed sessions for low latency
- [ ] Automatic result aggregation from team workers
- [ ] Resource limits per worker (CPU, memory, time)
- [ ] Naming convention and recycling for worker identities

**Technical Implementation:**
- Ephemeral session flag in task creation
- Worker pool management with warmup/cooldown
- Result aggregation and deduplication
- Resource quotas and OOM protection

**Inspired By:** Gas Town "Polecats" - ephemeral per-rig workers

**Priority:** 2 (High)  
**Status:** üìã Backlog  
**Notes:** Enables parallel exploration of solutions and work-swarming

---

### US-016: Multi-Model Provider Orchestration
**Description:** As a developer, I want to route different tasks to different LLM providers (Claude, GPT-4, Gemini) based on task characteristics and cost optimization.

**Acceptance Criteria:**
- [ ] Provider selection per task: `model: "claude-sonnet-4-5"` or `model: "gpt-4o"`
- [ ] Model fallback chain on failure or rate limiting
- [ ] Cost-aware routing (cheaper models for simple tasks)
- [ ] Capability-based routing (coding, reasoning, vision)
- [ ] Token usage tracking per provider
- [ ] Hot-swappable providers without session restart

**Technical Implementation:**
- Pi integration as first-class primitive
- Model registry with capabilities and costs
- Provider health checking and failover
- Unified API abstraction over different providers

**Inspired By:** Pi multi-provider support (15+ providers)

**Priority:** 1 (Critical)  
**Status:** üìã Design Phase  
**Notes:** Requires Pi SDK integration as core primitive

---

### US-017: Tree-Structured Session Navigation
**Description:** As a developer managing complex agent workflows, I want to navigate the conversation tree of an agent session to branch, fork, or rewind to previous states.

**Acceptance Criteria:**
- [ ] Tree visualization of session conversation history
- [ ] Branch creation from any point in history
- [ ] Session forking (create new session from existing state)
- [ ] Compact/summarize older branches to manage context window
- [ ] Navigation commands: `/tree`, `/fork`, `/branch`, `/compact`

**Technical Implementation:**
- Session state snapshots at each turn
- Tree data structure for conversation history
- Context window management with summarization
- Branch metadata and lineage tracking

**Inspired By:** Pi tree-structured sessions (`/tree`, `/fork` commands)

**Priority:** 2 (High)  
**Status:** üìã Backlog  
**Notes:** Critical for complex multi-step debugging and exploration

---

### US-018: Task-Level Todo Tracking
**Description:** As a developer, I want agents to maintain structured todo lists during task execution so I can track progress and ensure completion of all subtasks.

**Acceptance Criteria:**
- [ ] `todo_write` tool available to agents
- [ ] Persistent todo panel in dashboard showing active task lists
- [ ] Todo states: pending, in_progress, completed
- [ ] Automatic status updates based on agent actions
- [ ] Completion warnings when stopping with incomplete todos
- [ ] Todo export and audit trail

**Technical Implementation:**
- Todo tool in agent toolkit
- Real-time todo sync between agent and dashboard
- Todo persistence across session restarts
- Integration with task completion criteria

**Inspired By:** Pi `todo_write` tool, Loom task tracking

**Priority:** 2 (High)  
**Status:** üìã Backlog  
**Notes:** Improves agent reliability and task completeness

---

### US-019: Merge Queue with Conflict Resolution
**Description:** As a team lead, I want a managed merge queue that intelligently handles agent-generated changes, resolves conflicts, and maintains main branch stability.

**Acceptance Criteria:**
- [ ] Automated merge queue for agent-generated PRs/MRs
- [ ] Serial merging with automatic rebasing
- [ ] Conflict detection and escalation to human or "Refinery" agent
- [ ] Quality gates (tests, linting) before merge
- [ ] Rollback on merge failure
- [ ] Queue status dashboard with ETA estimates

**Technical Implementation:**
- Integration with GitHub/GitLab APIs
- Rebase automation with conflict detection
- Escalation workflow for unresolvable conflicts
- Quality gate integration (CI status checks)

**Inspired By:** Gas Town "Refinery" role, Merge Queue pattern

**Priority:** 2 (High)  
**Status:** üìã Backlog  
**Notes:** Essential for team workflows with multiple agents

---

### US-020: Session Persistence and Recovery
**Description:** As a developer, I want agent sessions to persist their state across restarts so that long-running tasks survive crashes and can be resumed later.

**Acceptance Criteria:**
- [ ] Automatic session state checkpointing
- [ ] Session resume from last checkpoint after crash
- [ ] Manual save/restore points with naming
- [ ] Session migration between agents
- [ ] Session archival for completed work
- [ ] "Prime" command for context recovery in existing sessions

**Technical Implementation:**
- Periodic state snapshots to persistent storage
- Resume protocol with context restoration
- Migration API for moving sessions between agents
- Archive lifecycle management

**Inspired By:** Gas Town "Hooks" persistence, Pi session management

**Priority:** 1 (Critical)  
**Status:** üìã Design Phase  
**Notes:** Foundational for reliable long-running agent workflows

---

### US-021: Agent Role System with Specialization
**Description:** As a platform operator, I want to define specialized agent roles (Mayor, Refinery, Witness, etc.) with specific prompts and capabilities for coordinated multi-agent workflows.

**Acceptance Criteria:**
- [ ] Role definition system with prompts, tools, and constraints
- [ ] Built-in roles: Coordinator, Worker, Reviewer, Monitor
- [ ] Custom role creation with YAML/JSON configuration
- [ ] Role-specific tool permissions
- [ ] Inter-role communication (mailbox/message passing)
- [ ] Role assignment in task/sling commands

**Technical Implementation:**
- Role registry with configuration schemas
- Prompt templating system
- Capability-based tool access control
- Message passing between agent sessions

**Inspired By:** Gas Town 7 worker roles (Mayor, Polecats, Refinery, Witness, etc.)

**Priority:** 2 (High)  
**Status:** üìã Backlog  
**Notes:** Enables complex coordinated workflows like Gas Town

---

### US-022: Feature Flags and Kill Switches
**Description:** As a platform operator, I want runtime feature flags and kill switches to control agent behavior and quickly disable problematic features without deployment.

**Acceptance Criteria:**
- [ ] Runtime feature toggle system
- [ ] A/B testing support for agent variants
- [ ] Gradual rollout (percentage-based)
- [ ] Emergency kill switches for immediate feature disable
- [ ] Feature flag evaluation in agent prompts
- [ ] Audit log of flag changes

**Technical Implementation:**
- Feature flag service with fast evaluation
- Flag state synchronization across instances
- Integration with agent context
- Emergency override mechanisms

**Inspired By:** Loom feature flags, experimentation infrastructure

**Priority:** 3 (Medium)  
**Status:** üìã Backlog  
**Notes:** Operational safety and experimentation capability

---

### US-023: Server-Side LLM Proxy
**Description:** As a security officer, I want API keys to remain server-side with a proxy architecture so that client-side code never has direct access to provider credentials.

**Acceptance Criteria:**
- [ ] Server-side LLM proxy for all provider calls
- [ ] Client authentication via session tokens, not API keys
- [ ] Rate limiting and quota enforcement at proxy layer
- [ ] Request/response logging for audit
- [ ] Provider failover handled transparently
- [ ] Token usage tracking per user/tenant

**Technical Implementation:**
- Proxy server with provider-specific adapters
- Token-based client authentication
- Circuit breaker for provider health
- Request transformation for different providers

**Inspired By:** Loom server-side LLM proxy architecture

**Priority:** 1 (Critical)  
**Status:** üìã Design Phase  
**Notes:** Security requirement for enterprise adoption

---

### US-024: Remote Execution Environments
**Description:** As a developer, I want to run agent sessions in remote sandboxed environments (containers, VMs) with resource isolation instead of local execution.

**Acceptance Criteria:**
- [ ] Remote execution backend integration (Kubernetes, Firecracker)
- [ ] On-demand pod/container provisioning
- [ ] Resource isolation (CPU, memory, network)
- [ ] Ephemeral environments with automatic cleanup
- [ ] File synchronization between local and remote
- [ ] SSH/remote access for debugging

**Technical Implementation:**
- Weaver-like remote execution service
- Kubernetes operator for session pods
- File sync via volume mounts or rsync
- Network policies for isolation

**Inspired By:** Loom "Weaver" remote execution, Gas Town pod isolation

**Priority:** 2 (High)  
**Status:** üìã Backlog  
**Notes:** Enables secure untrusted code execution

---

### US-025: Diff Viewer and Change Review
**Description:** As a developer, I want a visual diff viewer to review agent-generated changes before applying them, with the ability to accept, reject, or modify specific hunks.

**Acceptance Criteria:**
- [ ] Side-by-side diff viewer in dashboard
- [ ] Syntax highlighting for all supported languages
- [ ] Hunk-level accept/reject actions
- [ ] Inline editing of proposed changes
- [ ] Batch accept/reject for multiple files
- [ ] Export diff to patch file
- [ ] Integration with code review workflows

**Technical Implementation:**
- Diff generation and parsing
- Web-based diff viewer component
- Patch application with conflict detection
- Integration with GitHub/GitLab PR APIs

**Inspired By:** Conductor diff viewer, Gas Town review workflow

**Priority:** 2 (High)  
**Status:** üìã Backlog  
**Notes:** Essential for human-in-the-loop workflows

---

### US-026: Pi Registry and Instance Discovery
**Description:** As a platform operator, I want automatic discovery and registration of Pi instances so that Godel can dynamically scale across multiple Pi providers and instances.

**Acceptance Criteria:**
- [ ] PiRegistry component supports multiple discovery strategies (static, OpenClaw Gateway, Kubernetes, auto-spawn)
- [ ] Health monitoring for each Pi instance with heartbeat tracking
- [ ] Automatic failover when Pi instances become unhealthy
- [ ] Capacity tracking and load balancing across instances
- [ ] Instance metadata storage (provider, model, capabilities, version)
- [ ] API endpoints for manual instance registration and deregistration

**Technical Implementation:**
- Discovery strategies pluggable via configuration
- Health checks every 30 seconds with configurable timeout
- Capacity reports for intelligent task routing
- Instance selection based on load, capabilities, and health

**API Endpoints:**
```typescript
GET /api/v1/pi/instances          # List all Pi instances
POST /api/v1/pi/instances         # Register new instance
DELETE /api/v1/pi/instances/:id   # Deregister instance
GET /api/v1/pi/instances/:id/health  # Instance health status
```

**Priority:** 1 (Critical)  
**Status:** üìã Design Phase  
**Notes:** Required for multi-instance Pi orchestration and high availability

---

### US-027: Pi Session Lifecycle Management
**Description:** As a developer, I want full lifecycle management of Pi sessions including pause, resume, checkpoint, and migrate so that long-running agent work can survive interruptions.

**Acceptance Criteria:**
- [ ] Session creation with Pi configuration (provider, model, tools, system prompt)
- [ ] Pause and resume functionality with state preservation
- [ ] Automatic and manual checkpointing
- [ ] Session migration between Pi instances
- [ ] Session state persistence in Redis and PostgreSQL
- [ ] Recovery from last checkpoint on failure

**Technical Implementation:**
- PiSessionManager with state machine
- Checkpoints stored in Redis (hot) and PostgreSQL (cold)
- Automatic checkpointing every N messages
- Migration API for moving sessions between instances

**State Transitions:**
```
CREATING ‚Üí ACTIVE ‚Üí PAUSED ‚Üí RESUMING ‚Üí ACTIVE
   ‚Üì         ‚Üì       ‚Üì         ‚Üì
FAILED ‚Üê TERMINATING ‚Üê TERMINATED
```

**Priority:** 1 (Critical)  
**Status:** üìã Design Phase  
**Notes:** Critical for reliable long-running agent workflows

---

## 6. Functional Requirements

### 6.1 Core Orchestration

**FR-1: Priority Queue Semantics**
Task dispatch must preserve strict priority order and queue consistency across all lifecycle transitions.

**Detailed Requirements:**
- Four priority levels: `critical`, `high`, `medium`, `low`
- Strict ordering: All `critical` tasks complete before any `high` task starts
- Priority inheritance: Tasks spawned from high-priority tasks inherit priority
- Queue depth accuracy: Reported depth matches actual pending tasks

**Acceptance Criteria:**
```typescript
// Given: 5 critical, 10 high, 20 medium tasks pending
// When: dequeue() called 10 times
// Then: receive 5 critical, then 5 high tasks
```

---

**FR-2: Session Lifecycle Management**
Complete session lifecycle from creation through termination with state persistence.

**State Machine:**
```
CREATED ‚Üí INITIALIZING ‚Üí READY ‚Üí RUNNING ‚Üí COMPLETING ‚Üí COMPLETED
   ‚Üì           ‚Üì           ‚Üì          ‚Üì            ‚Üì
FAILED ‚Üê CANCELLED ‚Üê TIMEOUT ‚Üê ERROR ‚Üê‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**State Transitions:**
- `CREATED`: Session record created in database
- `INITIALIZING`: OpenClaw gateway contacted, session starting
- `READY`: Session active, waiting for tasks
- `RUNNING`: Task currently executing
- `COMPLETING`: Task finished, cleaning up
- `COMPLETED`: Session closed successfully
- `FAILED`: Session encountered unrecoverable error
- `CANCELLED`: Manual cancellation
- `TIMEOUT`: Session exceeded maximum duration
- `ERROR`: Unexpected error state

---

**FR-3: Retry and Dead Letter Handling**
Automatic retry with exponential backoff and dead-letter queue for permanent failures.

**Retry Configuration:**
```yaml
retry:
  max_attempts: 3
  backoff:
    type: exponential
    initial: 1000ms
    multiplier: 2
    max: 30000ms
  dead_letter:
    after_attempts: 3
    retention: 7d
    alert: true
```

**Dead Letter Processing:**
- Manual replay API
- Bulk retry with filters
- Export for analysis
- Automatic alerting

---

**FR-4: Scheduling and Load Balancing**
Intelligent task assignment based on agent capabilities, current load, and session affinity.

**Scheduling Factors:**
1. Priority (strict ordering)
2. Agent capabilities (matching required tools)
3. Current load (least-loaded first)
4. Session affinity (continue on same agent if possible)
5. Geographic proximity (if multi-region)

**Load Balancing Algorithms:**
- `round-robin`: Distribute evenly across all agents
- `least-loaded`: Assign to agent with lowest current load
- `capability-match`: Match task requirements to agent capabilities
- `session-affinity`: Prefer agent with existing related session

---

### 6.2 API Requirements

**FR-5: API Compatibility**
API must offer compatibility endpoints for both `/api` and `/api/v1` during migration.

**Compatibility Matrix:**
| Endpoint | `/api/v1` | `/api` | Status |
|----------|-----------|--------|--------|
| GET /health | ‚úÖ | ‚úÖ | Active |
| GET /teams | ‚úÖ | ‚úÖ | Active |
| POST /tasks | ‚úÖ | ‚úÖ | Active |
| GET /agents | ‚úÖ | ‚úÖ | Active |

**Deprecation Schedule:**
- Current: Both endpoints active
- Month 3: `/api` marked deprecated with headers
- Month 6: `/api` returns 301 redirect
- Month 9: `/api` removed

---

**FR-6: WebSocket Real-Time Events**
Event streaming for real-time dashboard updates and monitoring integration.

**Event Categories:**
- Task events: created, assigned, started, completed, failed, cancelled
- Agent events: connected, disconnected, status_change, load_change
- Session events: opened, closed, error, state_change
- System events: config_change, maintenance, alert

**Subscription Model:**
```javascript
// Client subscribes to specific event patterns
ws.send(JSON.stringify({
  action: 'subscribe',
  patterns: ['task.*', 'agent.*']
}));
```

---

**FR-7: Pagination and Filtering**
List endpoints support pagination, sorting, and filtering for large datasets.

**Standard Parameters:**
- `limit`: Results per page (default: 20, max: 100)
- `cursor`: Opaque cursor for pagination
- `sort`: Field to sort by (prefix with `-` for descending)
- `filter`: JSON filter object

**Example:**
```
GET /api/v1/tasks?limit=50&sort=-created_at&filter={"status":"pending","priority":"high"}
```

---

### 6.3 Integration Requirements

**FR-8: OpenClaw Protocol Compatibility**
Full compatibility with OpenClaw gateway protocol for session management.

**Protocol Requirements:**
- WebSocket connection management
- Request/response correlation
- Event subscription and routing
- Health probe integration
- Graceful shutdown handling

**Message Types:**
- `session.init`: Initialize new session
- `session.send`: Send message to session
- `session.kill`: Terminate session
- `session.status`: Get session status
- `event.subscribe`: Subscribe to events
- `event.unsubscribe`: Unsubscribe from events

---

**FR-9: Health Probe Integration**
Deterministic health endpoints for load balancers and orchestrators.

**Endpoint Specifications:**
```yaml
/health:
  method: GET
  response:
    status: 200 (healthy) | 503 (unhealthy)
    body:
      status: healthy|degraded|unhealthy
      version: "1.0.0"
      checks:
        database: { status: ok, latency_ms: 5 }
        redis: { status: ok, latency_ms: 2 }
        openclaw: { status: ok, instances: 5 }
      timestamp: "2026-01-15T10:30:00Z"

/health/live:
  method: GET
  response:
    status: 200
    body: { "status": "alive" }

/health/ready:
  method: GET
  response:
    status: 200 (ready) | 503 (not ready)
    body:
      status: ready|not_ready
      reason: "Database connection failed"
```

---

## 7. Non-Functional Requirements

### 7.1 Performance Requirements

**NFR-1: Latency Targets**
Response time requirements for different operation types.

| Operation | p50 | p95 | p99 | Notes |
|-----------|-----|-----|-----|-------|
| API Response | <50ms | <100ms | <200ms | Excluding DB queries |
| Task Dispatch | <10ms | <50ms | <100ms | Queue dequeue operation |
| Session Start | <500ms | <2s | <5s | Includes OpenClaw negotiation |
| Health Check | <10ms | <20ms | <50ms | Probe response time |
| WebSocket Event | <5ms | <10ms | <20ms | Internal routing |

**NFR-2: Throughput Requirements**
System capacity at different scale targets.

| Metric | 10 Sessions | 25 Sessions | 50 Sessions |
|--------|-------------|-------------|-------------|
| Tasks/sec | 50 | 100 | 200 |
| Concurrent tasks | 100 | 250 | 500 |
| Events/sec | 500 | 1,000 | 2,000 |
| API requests/sec | 1,000 | 2,000 | 5,000 |

**NFR-3: Resource Utilization**
Target resource efficiency at scale.

- **CPU:** <70% average utilization at target load
- **Memory:** <80% of available RAM
- **Database Connections:** <80% of pool capacity
- **Redis Memory:** <70% of allocated memory

---

### 7.2 Scalability Requirements

**NFR-4: Horizontal Scaling**
System scales horizontally with additional instances.

**Scaling Dimensions:**
- **API Servers:** Stateless, scale behind load balancer
- **Queue Workers:** Shard by task ID hash
- **WebSocket Servers:** Sticky sessions or pub/sub sync
- **OpenClaw Gateways:** Federation with routing layer

**NFR-5: Data Growth**
Handle increasing data volume without degradation.

| Data Type | Growth Rate | Retention | Strategy |
|-----------|-------------|-----------|----------|
| Tasks | 10K/day | 90 days | Archive to cold storage |
| Events | 100K/day | 30 days | Aggressive TTL |
| Logs | 1GB/day | 7 days | External log aggregation |
| Metrics | 10MB/day | 1 year | Downsample after 30 days |

---

### 7.3 Reliability Requirements

**NFR-6: Availability Targets**
Uptime and reliability commitments.

- **Target Availability:** 99.9% (8.76 hours downtime/year)
- **Planned Maintenance:** <4 hours/month during off-peak
- **Recovery Time Objective (RTO):** <15 minutes
- **Recovery Point Objective (RPO):** <5 minutes

**NFR-7: Fault Tolerance**
System behavior during component failures.

| Failure Scenario | Behavior | Recovery |
|------------------|----------|----------|
| Single API server crash | Traffic routed to healthy instances | Auto-restart |
| Database connection loss | Queue accepts tasks, mark degraded | Retry connection |
| Redis unavailable | Fallback to in-memory queue (limited) | Alert operator |
| OpenClaw instance failure | Tasks rerouted to healthy instances | Auto-detect, drain |
| Network partition | Split-brain prevention via consensus | Manual intervention |

---

### 7.4 Maintainability Requirements

**NFR-8: Code Quality**
Standards for codebase maintainability.

- **Test Coverage:** >80% unit test coverage
- **Type Safety:** 100% TypeScript strict mode
- **Documentation:** JSDoc for all public APIs
- **Linting:** Zero warnings in CI

**NFR-9: Deployment Automation**
Fully automated deployment pipeline.

- **Build Time:** <5 minutes
- **Test Time:** <10 minutes (parallel)
- **Deploy Time:** <2 minutes
- **Rollback Time:** <1 minute

---

## 8. Security Requirements

### 8.1 Authentication

**SR-1: JWT Token Security**
JSON Web Token implementation requirements.

**Token Specifications:**
```yaml
jwt:
  algorithm: HS256
  secret_length: 256 bits minimum
  access_token_ttl: 15 minutes
  refresh_token_ttl: 7 days
  issuer: "godel"
  audience: "godel-api"
  required_claims:
    - sub (user id)
    - iss (issuer)
    - aud (audience)
    - exp (expiration)
    - iat (issued at)
    - jti (token id)
```

**SR-2: API Key Authentication**
Alternative authentication for service accounts.

**API Key Format:**
```
dk_live_<base64url_encoded_random_32bytes>
dk_test_<base64url_encoded_random_32bytes>
```

**Key Management:**
- Keys stored hashed (SHA-256) in database
- Prefix-based environment detection
- Rotation support (grace period for old keys)
- Audit logging for all key usage

---

### 8.2 Authorization

**SR-3: Role-Based Access Control (RBAC)**
Permission system with predefined roles.

**Roles:**
| Role | Permissions |
|------|-------------|
| admin | Full access |
| operator | Read + execute operations |
| developer | Read + create tasks |
| viewer | Read-only |

**Permission Matrix:**
| Resource | create | read | update | delete | execute |
|----------|--------|------|--------|--------|---------|
| tasks | operator | all | operator | admin | operator |
| agents | admin | all | admin | admin | operator |
| sessions | operator | all | - | operator | operator |
| config | admin | admin | admin | - | - |

---

### 8.3 Data Protection

**SR-4: Encryption in Transit**
All communications encrypted.

- **API:** TLS 1.3 minimum
- **WebSocket:** WSS (WebSocket Secure)
- **Database:** SSL/TLS connection required
- **Redis:** TLS connection required
- **OpenClaw:** Token-based auth over secure channel

**SR-5: Encryption at Rest**
Sensitive data encrypted when stored.

| Data Type | Encryption Method | Key Management |
|-----------|-------------------|----------------|
| JWT Secrets | AES-256-GCM | Environment variable |
| API Keys | SHA-256 hash | Database |
| Database | Transparent encryption | Database provider |
| Session tokens | AES-256-GCM | KMS |

**SR-6: Secret Management**
Secure handling of credentials and secrets.

- No secrets in code or configuration files
- Environment variable injection at runtime
- Secret rotation every 90 days
- Audit log of all secret access

---

### 8.4 Audit and Compliance

**SR-7: Audit Logging**
Comprehensive audit trail of all operations.

**Logged Events:**
- Authentication attempts (success/failure)
- Authorization failures
- Configuration changes
- Task lifecycle events
- Session operations
- Admin actions

**Log Format:**
```json
{
  "timestamp": "2026-01-15T10:30:00Z",
  "level": "info",
  "event": "task.created",
  "user_id": "user_123",
  "ip_address": "192.168.1.1",
  "user_agent": "Mozilla/5.0...",
  "resource": "task",
  "action": "create",
  "resource_id": "task_456",
  "details": { "priority": "high" }
}
```

**SR-8: Compliance Considerations**
Regulatory compliance preparation.

- **GDPR:** Right to deletion, data portability
- **SOC 2:** Access controls, audit trails, change management
- **HIPAA:** If handling healthcare data (encryption, access logs)

---

## 9. Architecture & Technical Approach

### 9.1 System Architecture Overview

**Approach:** Keep current modular architecture and harden high-risk seams first.

**Architecture Layers:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CLIENT LAYER                                ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ Dashboard ‚îÇ  ‚îÇ   CLI    ‚îÇ  ‚îÇ   SDK    ‚îÇ  ‚îÇ External ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ   (UI)   ‚îÇ  ‚îÇ          ‚îÇ  ‚îÇ          ‚îÇ  ‚îÇ  Systems ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ            ‚îÇ            ‚îÇ            ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    API LAYER                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                    Load Balancer                          ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                       ‚îÇ                                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ              API Servers (Fastify/Express)                ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Auth   ‚îÇ ‚îÇ  Tasks  ‚îÇ ‚îÇ Agents  ‚îÇ ‚îÇ  Admin  ‚îÇ        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇMiddleware‚îÇ ‚îÇ Routes  ‚îÇ ‚îÇ Routes  ‚îÇ ‚îÇ Routes  ‚îÇ        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               ORCHESTRATION LAYER                               ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  Queue   ‚îÇ ‚îÇ Scheduler‚îÇ ‚îÇ Lifecycle‚îÇ ‚îÇ Federation‚îÇ          ‚îÇ
‚îÇ  ‚îÇ Manager  ‚îÇ ‚îÇ          ‚îÇ ‚îÇ Manager  ‚îÇ ‚îÇ  Router   ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ            ‚îÇ            ‚îÇ            ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                         ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              INTEGRATION LAYER                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ OpenClaw ‚îÇ ‚îÇ Event    ‚îÇ ‚îÇ Metrics  ‚îÇ ‚îÇ   Bus    ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ Adapter  ‚îÇ ‚îÇ Handler  ‚îÇ ‚îÇ Collector‚îÇ ‚îÇ          ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     DATA LAYER                                  ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇPostgreSQL‚îÇ ‚îÇ  Redis   ‚îÇ ‚îÇ  Object  ‚îÇ ‚îÇ  Logs    ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ (State)  ‚îÇ ‚îÇ (Queue)  ‚îÇ ‚îÇ Storage  ‚îÇ ‚îÇ          ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 9.2 Architecture Decisions

**Decision 1: Fastify as Canonical Server**
- **Context:** Both Express and Fastify implementations exist
- **Decision:** Promote Fastify to canonical production server
- **Rationale:** Better performance, built-in async/await support, modern plugin architecture
- **Consequences:** Deprecate Express paths, migrate all routes to Fastify

**Decision 2: Redis for Queue State**
- **Context:** Queue needs fast, atomic operations
- **Decision:** Use Redis with Lua scripts for atomic queue operations
- **Rationale:** High performance, atomic operations, proven at scale
- **Consequences:** Redis becomes critical dependency, requires HA setup for production

**Decision 3: PostgreSQL for Authoritative State**
- **Context:** Need durable, consistent state for sessions and tasks
- **Decision:** PostgreSQL for primary state, SQLite for local development
- **Rationale:** ACID compliance, mature tooling, horizontal read scaling
- **Consequences:** Database schema migrations required, connection pooling needed

**Decision 4: Event-Driven Architecture**
- **Context:** Need loose coupling between components
- **Decision:** In-process event bus with Redis pub/sub for multi-instance
- **Rationale:** Decoupled components, easy testing, scalable
- **Consequences:** Event ordering guarantees, eventual consistency considerations

### 9.3 Component Responsibilities

**API Layer:**
- Request validation and routing
- Authentication and authorization
- Rate limiting
- Response formatting

**Orchestration Layer:**
- Task queue management
- Scheduling decisions
- Session lifecycle
- Federation routing

**Integration Layer:**
- OpenClaw protocol handling
- External system integration
- Event transformation
- Metrics collection

**Data Layer:**
- Persistent state storage
- Caching
- Queue storage
- Log aggregation

---

## 10. API Contract Specifications

### 10.1 OpenAPI 3.1 Specification

```yaml
openapi: 3.1.0
info:
  title: Godel API
  version: 1.0.0
  description: Meta-orchestrator API for OpenClaw session management
  contact:
    name: Godel Team
    email: api@godel.dev

servers:
  - url: http://localhost:7373/api/v1
    description: Local development
  - url: https://api.godel.dev/v1
    description: Production

security:
  - bearerAuth: []
  - apiKeyAuth: []

paths:
  /health:
    get:
      summary: Health check
      security: []
      responses:
        '200':
          description: System healthy
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/HealthResponse'
        '503':
          description: System unhealthy

  /tasks:
    get:
      summary: List tasks
      parameters:
        - name: limit
          in: query
          schema: { type: integer, default: 20 }
        - name: cursor
          in: query
          schema: { type: string }
        - name: status
          in: query
          schema: { type: string, enum: [pending, running, completed, failed] }
        - name: priority
          in: query
          schema: { type: string, enum: [critical, high, medium, low] }
      responses:
        '200':
          description: Task list
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/TaskList'

    post:
      summary: Create task
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/TaskCreate'
      responses:
        '201':
          description: Task created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Task'

  /tasks/{id}:
    get:
      summary: Get task
      parameters:
        - name: id
          in: path
          required: true
          schema: { type: string }
      responses:
        '200':
          description: Task details
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/Task'
        '404':
          description: Task not found

  /agents:
    get:
      summary: List agents
      responses:
        '200':
          description: Agent list
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AgentList'

  /agents/{id}/status:
    get:
      summary: Get agent status
      parameters:
        - name: id
          in: path
          required: true
          schema: { type: string }
      responses:
        '200':
          description: Agent status
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/AgentStatus'

  /sessions:
    get:
      summary: List sessions
      responses:
        '200':
          description: Session list

    post:
      summary: Create session
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/SessionCreate'
      responses:
        '201':
          description: Session created

components:
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT
    apiKeyAuth:
      type: apiKey
      in: header
      name: X-API-Key

  schemas:
    HealthResponse:
      type: object
      required: [status, timestamp]
      properties:
        status:
          type: string
          enum: [healthy, degraded, unhealthy]
        version:
          type: string
        checks:
          type: object
          properties:
            database:
              type: object
              properties:
                status: { type: string }
                latency_ms: { type: number }
            redis:
              type: object
              properties:
                status: { type: string }
                latency_ms: { type: number }
        timestamp:
          type: string
          format: date-time

    Task:
      type: object
      required: [id, status, priority, created_at]
      properties:
        id: { type: string }
        status:
          type: string
          enum: [pending, assigned, running, completed, failed, cancelled, dead_letter]
        priority:
          type: string
          enum: [critical, high, medium, low]
        agent_id: { type: string, nullable: true }
        session_id: { type: string, nullable: true }
        payload: { type: object }
        result: { type: object, nullable: true }
        error: { type: string, nullable: true }
        attempt_count: { type: integer, default: 0 }
        created_at: { type: string, format: date-time }
        updated_at: { type: string, format: date-time }
        scheduled_at: { type: string, format: date-time, nullable: true }

    TaskCreate:
      type: object
      required: [payload]
      properties:
        payload: { type: object }
        priority:
          type: string
          enum: [critical, high, medium, low]
          default: medium
        scheduled_at: { type: string, format: date-time, nullable: true }

    TaskList:
      type: object
      properties:
        items:
          type: array
          items:
            $ref: '#/components/schemas/Task'
        next_cursor: { type: string, nullable: true }
        total: { type: integer }

    Agent:
      type: object
      required: [id, status, capabilities]
      properties:
        id: { type: string }
        status:
          type: string
          enum: [idle, busy, offline, error]
        capabilities:
          type: array
          items: { type: string }
        current_load: { type: integer }
        max_capacity: { type: integer }
        last_heartbeat: { type: string, format: date-time }

    AgentList:
      type: object
      properties:
        items:
          type: array
          items:
            $ref: '#/components/schemas/Agent'

    AgentStatus:
      type: object
      properties:
        agent: { $ref: '#/components/schemas/Agent' }
        active_tasks: { type: integer }
        queue_depth: { type: integer }

    SessionCreate:
      type: object
      required: [agent_id, openclaw_config]
      properties:
        agent_id: { type: string }
        openclaw_config:
          type: object
          properties:
            profile: { type: string }
            workspace: { type: string }
            env_vars: { type: object }
```

### 10.2 Error Codes

| Code | HTTP Status | Description | Retryable |
|------|-------------|-------------|-----------|
| `invalid_request` | 400 | Malformed request | No |
| `unauthorized` | 401 | Authentication required | No |
| `forbidden` | 403 | Insufficient permissions | No |
| `not_found` | 404 | Resource not found | No |
| `conflict` | 409 | Resource conflict | Yes |
| `rate_limited` | 429 | Too many requests | Yes |
| `internal_error` | 500 | Server error | Yes |
| `service_unavailable` | 503 | Temporarily unavailable | Yes |
| `gateway_timeout` | 504 | Upstream timeout | Yes |

### 10.3 Rate Limiting

**Limits by Tier:**
| Tier | Requests/min | Burst | WebSocket Connections |
|------|--------------|-------|----------------------|
| Free | 60 | 10 | 1 |
| Pro | 600 | 100 | 5 |
| Enterprise | 6000 | 1000 | Unlimited |

**Headers:**
- `X-RateLimit-Limit`: Request limit
- `X-RateLimit-Remaining`: Remaining requests
- `X-RateLimit-Reset`: Unix timestamp of reset

---

## 11. Data Model & Storage

### 11.1 Database Schema

```sql
-- Core task table
CREATE TABLE tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tenant_id UUID NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',
    status VARCHAR(20) NOT NULL DEFAULT 'pending',
    priority VARCHAR(10) NOT NULL DEFAULT 'medium',
    agent_id UUID REFERENCES agents(id),
    session_id UUID REFERENCES sessions(id),
    payload JSONB NOT NULL DEFAULT '{}',
    result JSONB,
    error TEXT,
    attempt_count INTEGER NOT NULL DEFAULT 0,
    max_attempts INTEGER NOT NULL DEFAULT 3,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    scheduled_at TIMESTAMP WITH TIME ZONE,
    started_at TIMESTAMP WITH TIME ZONE,
    completed_at TIMESTAMP WITH TIME ZONE,
    dead_lettered_at TIMESTAMP WITH TIME ZONE,
    CONSTRAINT valid_priority CHECK (priority IN ('critical', 'high', 'medium', 'low')),
    CONSTRAINT valid_status CHECK (status IN ('pending', 'assigned', 'running', 'completed', 'failed', 'cancelled', 'dead_letter'))
);

CREATE INDEX idx_tasks_status ON tasks(status);
CREATE INDEX idx_tasks_priority ON tasks(priority);
CREATE INDEX idx_tasks_agent_id ON tasks(agent_id);
CREATE INDEX idx_tasks_tenant_id ON tasks(tenant_id);
CREATE INDEX idx_tasks_created_at ON tasks(created_at DESC);

-- Agent registry
CREATE TABLE agents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tenant_id UUID NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',
    name VARCHAR(255) NOT NULL,
    status VARCHAR(20) NOT NULL DEFAULT 'offline',
    capabilities JSONB NOT NULL DEFAULT '[]',
    current_load INTEGER NOT NULL DEFAULT 0,
    max_capacity INTEGER NOT NULL DEFAULT 10,
    openclaw_endpoint VARCHAR(500),
    openclaw_token_hash VARCHAR(255),
    last_heartbeat TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    CONSTRAINT valid_agent_status CHECK (status IN ('idle', 'busy', 'offline', 'error'))
);

CREATE INDEX idx_agents_status ON agents(status);
CREATE INDEX idx_agents_tenant_id ON agents(tenant_id);

-- Session tracking
CREATE TABLE sessions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tenant_id UUID NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',
    agent_id UUID NOT NULL REFERENCES agents(id),
    openclaw_session_id VARCHAR(255),
    status VARCHAR(20) NOT NULL DEFAULT 'created',
    config JSONB NOT NULL DEFAULT '{}',
    context_size INTEGER DEFAULT 0,
    max_context_size INTEGER DEFAULT 128000,
    started_at TIMESTAMP WITH TIME ZONE,
    ended_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    CONSTRAINT valid_session_status CHECK (status IN ('created', 'initializing', 'ready', 'running', 'completing', 'completed', 'failed', 'cancelled', 'timeout', 'error'))
);

CREATE INDEX idx_sessions_agent_id ON sessions(agent_id);
CREATE INDEX idx_sessions_status ON sessions(status);
CREATE INDEX idx_sessions_tenant_id ON sessions(tenant_id);

-- OpenClaw instance registry (federation)
CREATE TABLE openclaw_instances (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    endpoint VARCHAR(500) NOT NULL UNIQUE,
    region VARCHAR(50),
    zone VARCHAR(50),
    version VARCHAR(50),
    capabilities JSONB NOT NULL DEFAULT '[]',
    health_status VARCHAR(20) NOT NULL DEFAULT 'unknown',
    current_sessions INTEGER NOT NULL DEFAULT 0,
    max_sessions INTEGER NOT NULL DEFAULT 10,
    cpu_percent DECIMAL(5,2),
    memory_percent DECIMAL(5,2),
    last_health_check TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    CONSTRAINT valid_health CHECK (health_status IN ('healthy', 'degraded', 'unhealthy', 'unknown'))
);

CREATE INDEX idx_openclaw_health ON openclaw_instances(health_status);
CREATE INDEX idx_openclaw_region ON openclaw_instances(region);

-- Event log for audit trail
CREATE TABLE events (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tenant_id UUID NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',
    event_type VARCHAR(100) NOT NULL,
    resource_type VARCHAR(50) NOT NULL,
    resource_id UUID,
    user_id UUID,
    payload JSONB NOT NULL DEFAULT '{}',
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_events_type ON events(event_type);
CREATE INDEX idx_events_resource ON events(resource_type, resource_id);
CREATE INDEX idx_events_created_at ON events(created_at DESC);

-- Users and authentication
CREATE TABLE users (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    tenant_id UUID NOT NULL DEFAULT '00000000-0000-0000-0000-000000000000',
    email VARCHAR(255) NOT NULL UNIQUE,
    password_hash VARCHAR(255),
    role VARCHAR(20) NOT NULL DEFAULT 'viewer',
    api_key_hash VARCHAR(255),
    last_login TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    CONSTRAINT valid_role CHECK (role IN ('admin', 'operator', 'developer', 'viewer'))
);

CREATE INDEX idx_users_tenant ON users(tenant_id);
CREATE INDEX idx_users_email ON users(email);

-- Row Level Security Policies
ALTER TABLE tasks ENABLE ROW LEVEL SECURITY;
ALTER TABLE agents ENABLE ROW LEVEL SECURITY;
ALTER TABLE sessions ENABLE ROW LEVEL SECURITY;
ALTER TABLE events ENABLE ROW LEVEL SECURITY;

CREATE POLICY tenant_isolation_tasks ON tasks
    USING (tenant_id = current_setting('app.current_tenant')::UUID);

CREATE POLICY tenant_isolation_agents ON agents
    USING (tenant_id = current_setting('app.current_tenant')::UUID);

CREATE POLICY tenant_isolation_sessions ON sessions
    USING (tenant_id = current_setting('app.current_tenant')::UUID);
```

### 11.2 Redis Data Structures

**Queue Keys:**
```
godel:{tenant}:queue:critical    # Sorted set: score = timestamp, member = task_id
godel:{tenant}:queue:high        # Sorted set: score = timestamp, member = task_id
godel:{tenant}:queue:medium      # Sorted set: score = timestamp, member = task_id
godel:{tenant}:queue:low         # Sorted set: score = timestamp, member = task_id
godel:{tenant}:queue:pending     # Set: all pending task_ids
godel:{tenant}:queue:assigned    # Hash: task_id -> agent_id
godel:{tenant}:queue:running     # Hash: task_id -> {agent_id, started_at}
godel:{tenant}:queue:scheduled   # Sorted set: score = scheduled_at, member = task_id
godel:{tenant}:queue:dead_letter # List: failed task_ids
```

**Agent State:**
```
godel:{tenant}:agent:{id}:load        # String: current load
godel:{tenant}:agent:{id}:status      # String: idle|busy|offline|error
godel:{tenant}:agent:{id}:heartbeat   # String: ISO timestamp
godel:{tenant}:agents:idle            # Set: idle agent_ids
godel:{tenant}:agents:busy            # Set: busy agent_ids
```

**Session State:**
```
godel:{tenant}:session:{id}:status    # String: session status
godel:{tenant}:session:{id}:agent     # String: assigned agent_id
godel:{tenant}:sessions:active        # Set: active session_ids
```

**Rate Limiting:**
```
godel:ratelimit:{key}                 # String: request count with TTL
```

---

## 12. Observability & Monitoring

### 12.1 Metrics

**Core Metrics (Prometheus):**
```yaml
# Task metrics
dash_tasks_created_total:
  type: counter
  labels: [priority, tenant]
  
dash_tasks_completed_total:
  type: counter
  labels: [priority, status]
  
dash_task_duration_seconds:
  type: histogram
  labels: [priority]
  buckets: [0.1, 0.5, 1, 5, 10, 30, 60, 300]

dash_queue_depth:
  type: gauge
  labels: [priority, tenant]

# Agent metrics
dash_agents_connected:
  type: gauge
  labels: [status, tenant]

dash_agent_load_percent:
  type: gauge
  labels: [agent_id]

dash_agent_heartbeat_latency_seconds:
  type: histogram

# Session metrics  
dash_sessions_active:
  type: gauge
  labels: [status, tenant]

dash_session_duration_seconds:
  type: histogram
  buckets: [60, 300, 600, 1800, 3600]

# API metrics
dash_api_requests_total:
  type: counter
  labels: [method, route, status]

dash_api_duration_seconds:
  type: histogram
  labels: [route]

# Error metrics
dash_errors_total:
  type: counter
  labels: [type, component]
```

### 12.2 Logging

**Log Levels:**
- `ERROR`: Failures requiring immediate attention
- `WARN`: Degraded conditions, retry attempts
- `INFO`: Normal operations, state changes
- `DEBUG`: Detailed execution flow
- `TRACE`: Request/response bodies

**Structured Log Format:**
```json
{
  "timestamp": "2026-01-15T10:30:00.000Z",
  "level": "info",
  "message": "Task assigned to agent",
  "service": "godel-api",
  "version": "1.0.0",
  "trace_id": "abc123",
  "span_id": "def456",
  "tenant_id": "tenant_123",
  "user_id": "user_456",
  "task_id": "task_789",
  "agent_id": "agent_abc",
  "duration_ms": 15,
  "context": {
    "priority": "high",
    "queue_depth": 42
  }
}
```

### 12.3 Distributed Tracing

**Trace Context Propagation:**
- HTTP: `traceparent` and `tracestate` headers
- WebSocket: Initial connection headers, message metadata
- Internal: AsyncLocalStorage for Node.js

**Span Types:**
- `api.request`: HTTP request handling
- `queue.operation`: Queue dequeue/enqueue
- `session.lifecycle`: Session state transitions
- `openclaw.rpc`: OpenClaw gateway calls
- `database.query`: Database operations

### 12.4 Alerting Rules

**Critical Alerts (Page On-Call):**
```yaml
- alert: HighErrorRate
  expr: rate(dash_errors_total[5m]) > 10
  for: 2m
  
- alert: QueueStalled
  expr: dash_queue_depth > 1000 and rate(dash_tasks_completed_total[5m]) == 0
  for: 5m
  
- alert: AgentMassDisconnect
  expr: rate(dash_agents_connected[1m]) < -5
  for: 1m
  
- alert: DatabaseConnectionFailure
  expr: up{job="godel-api"} == 0
  for: 30s
```

**Warning Alerts (Ticket/Slack):**
```yaml
- alert: ElevatedLatency
  expr: histogram_quantile(0.95, dash_api_duration_seconds) > 0.5
  for: 5m
  
- alert: HighQueueDepth
  expr: dash_queue_depth > 500
  for: 10m
  
- alert: LowAgentUtilization
  expr: avg(dash_agent_load_percent) < 20
  for: 30m
```

---

## 13. Testing Strategy

### 13.1 Test Pyramid

```
       ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ   E2E   ‚îÇ  <- 5% of tests, critical user journeys
       ‚îÇ  (slow) ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
       ‚îÇ   Int   ‚îÇ  <- 15% of tests, module integration
       ‚îÇ (medium)‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
       ‚îÇ  Unit   ‚îÇ  <- 80% of tests, fast feedback
       ‚îÇ  (fast) ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 13.2 Test Categories

**Unit Tests:**
- Location: `tests/unit/**/*.test.ts`
- Coverage Target: >80%
- Execution Time: <5 minutes
- Dependencies: None (fully mocked)

**Integration Tests (Mocked):**
- Location: `tests/integration/*.test.ts`
- Dependencies: Mocked external services
- Gating: Run on every PR

**Integration Tests (Live):**
- Location: `tests/integration/live/*.test.ts`
- Dependencies: PostgreSQL, Redis, OpenClaw
- Gating: `RUN_LIVE_INTEGRATION_TESTS=true`
- Frequency: Pre-release, nightly

**E2E Tests:**
- Location: `tests/e2e/**/*.test.ts`
- Scope: Full user journeys
- Gating: `RUN_E2E_TESTS=true`
- Frequency: Pre-release

**Load Tests:**
- Location: `tests/load/**/*.test.ts`
- Profiles: 10/25/50 session targets
- Tool: k6 or Artillery
- Frequency: Weekly, pre-release

### 13.3 Test Data Management

**Fixtures:**
```typescript
// tests/fixtures/tasks.ts
export const createTaskFixture = (overrides = {}) => ({
  id: `task_${nanoid()}`,
  priority: 'medium',
  status: 'pending',
  payload: { type: 'test' },
  ...overrides
});
```

**Test Database:**
- Separate database per test run
- Migrations run before tests
- Cleanup after each test (transaction rollback or truncate)

### 13.4 Release Gates

**Stage 1: Pre-Build**
```bash
npm run lint
npm run typecheck
npm run security:audit
```

**Stage 2: Unit Tests**
```bash
npm test -- --testPathPattern=unit
```

**Stage 3: Integration (Mocked)**
```bash
npm test -- --testPathPattern=integration
```

**Stage 4: Integration (Live)**
```bash
RUN_LIVE_INTEGRATION_TESTS=true npm test -- --testPathPattern=integration/live
```

**Stage 5: Load Test**
```bash
npm run test:load -- --sessions=25
```

**Stage 6: Security Scan**
```bash
npm run security:scan
```

---

## 14. Deployment & Operations

### 14.1 Infrastructure Requirements

**Production Minimum:**
| Component | Spec | Count | Notes |
|-----------|------|-------|-------|
| API Server | 2 vCPU, 4GB RAM | 2+ | Stateless, behind LB |
| PostgreSQL | 4 vCPU, 16GB RAM | 1 primary, 1 replica | SSD storage |
| Redis | 2 vCPU, 4GB RAM | 1 primary, 1 replica | Persistence enabled |
| OpenClaw | 4 vCPU, 8GB RAM | 10-50 | Per instance spec |

**Recommended (50 sessions):**
| Component | Spec | Count |
|-----------|------|-------|
| API Server | 4 vCPU, 8GB RAM | 3 |
| PostgreSQL | 8 vCPU, 32GB RAM | 1 primary, 2 replicas |
| Redis | 4 vCPU, 8GB RAM | 3 (cluster mode) |
| OpenClaw | 4 vCPU, 8GB RAM | 50 |

### 14.2 Environment Promotion

```
Local ‚Üí Dev ‚Üí Staging ‚Üí Canary ‚Üí Production
```

**Local:**
- SQLite for quick iteration
- Single OpenClaw instance
- Hot reload enabled

**Dev:**
- PostgreSQL (shared)
- Redis (shared)
- 2-5 OpenClaw instances

**Staging:**
- Production-like setup
- 5-10 OpenClaw instances
- Full test suite runs

**Canary:**
- 5% of production traffic
- 30-minute observation window
- Automatic rollback on error threshold

**Production:**
- Full capacity
- Multi-region if applicable
- 24/7 on-call

### 14.3 Configuration Management

**Environment Variables:**
```bash
# Server
DASH_PORT=7373
DASH_HOST=0.0.0.0
DASH_NODE_ENV=production

# Database
DASH_DATABASE_URL=postgresql://user:pass@localhost:5432/godel
DASH_DATABASE_POOL_SIZE=20

# Redis
DASH_REDIS_URL=redis://localhost:6379
DASH_REDIS_CLUSTER=false

# Auth
DASH_JWT_SECRET=<256-bit-secret>
DASH_JWT_ISSUER=godel
DASH_JWT_AUDIENCE=godel-api

# OpenClaw
DASH_OPENCLAW_COMMAND=openclaw
DASH_OPENCLAW_MAX_SESSIONS=50
DASH_OPENCLAW_DAEMON_ENABLED=true

# Observability
DASH_LOG_LEVEL=info
DASH_METRICS_ENABLED=true
DASH_TRACING_ENABLED=true
```

**Secrets Management:**
- Development: `.env` file (gitignored)
- Staging: Environment-specific secret store
- Production: HashiCorp Vault or AWS Secrets Manager

### 14.4 Operational Runbooks

**Runbook 1: Queue Backlog Alert**
```markdown
## Symptoms
- Alert: `dash_queue_depth > 500`
- Dashboard shows high pending task count

## Diagnosis
1. Check agent status: `GET /api/v1/agents`
2. Check if agents are processing: Look for `running` tasks
3. Check OpenClaw instance health

## Resolution
1. If agents offline: Restart agent processes
2. If OpenClaw instances unhealthy: Drain and restart
3. If capacity exhausted: Scale OpenClaw pool

## Escalation
- If unresolved in 15 minutes: Page on-call
```

**Runbook 2: Database Connection Issues**
```markdown
## Symptoms
- Health check failing on database probe
- Error logs: `connection refused` or `timeout`

## Diagnosis
1. Check database server status
2. Verify connection pool metrics
3. Check for connection leaks

## Resolution
1. Restart API servers to reset connections
2. Increase pool size if sustained load
3. Check for long-running queries

## Escalation
- If primary database down: Failover to replica
```

---

## 15. Disaster Recovery

### 15.1 Backup Strategy

**Database:**
- Full backup: Daily at 02:00 UTC
- Incremental: Every 6 hours
- Retention: 30 days
- Storage: S3 with cross-region replication

**Redis:**
- RDB snapshots: Every 15 minutes
- AOF enabled for durability
- Backup to S3: Hourly

**Configuration:**
- Infrastructure as Code (Terraform/Pulumi)
- Version controlled in Git
- Automated state backup

### 15.2 Recovery Procedures

**RTO: 15 minutes, RPO: 5 minutes**

**Scenario 1: Database Failure**
```markdown
1. Detect: Health checks failing, alerts firing
2. Promote: Promote read replica to primary (<2 min)
3. Redirect: Update connection strings or DNS
4. Verify: Run smoke tests
5. Notify: Update status page
```

**Scenario 2: Complete Region Failure**
```markdown
1. Detect: Multi-service alerts, external monitoring
2. Failover: Activate standby region
3. Restore: Restore database from cross-region backup
4. Verify: Full system validation
5. Communicate: Customer notification
```

**Scenario 3: Data Corruption**
```markdown
1. Stop: Halt writes to prevent further damage
2. Assess: Identify corruption scope and timeline
3. Restore: Point-in-time recovery to known good state
4. Reconcile: Replay valid transactions since recovery point
5. Verify: Data integrity checks
```

### 15.3 Rollback Procedures

**Code Rollback:**
```bash
# Kubernetes
kubectl rollout undo deployment/godel-api

# Docker Compose
docker-compose pull godel-api:previous
docker-compose up -d

# Manual
systemctl stop godel
cd /opt/godel && git checkout <previous-tag>
npm install && npm run build
systemctl start godel
```

**Database Rollback:**
```bash
# If migration failed
npx knex migrate:rollback

# Point-in-time recovery
pg_restore --target-time "2026-01-15 10:00:00" backup.dump
```

---

## 16. Success Metrics

### 16.1 Technical Metrics

**Reliability:**
| Metric | Target | Measurement |
|--------|--------|-------------|
| Task Success Rate | >99.9% | `completed / (completed + failed)` |
| System Uptime | >99.9% | External health probe |
| Error Rate | <0.1% | 5xx responses / total requests |
| Mean Time To Detect | <30s | Alert firing time |
| Mean Time To Resolve | <5min | Incident resolution |

**Performance:**
| Metric | Target | Measurement |
|--------|--------|-------------|
| API p95 Latency | <100ms | API gateway metrics |
| Task Dispatch Latency | <50ms | Queue dequeue timing |
| Session Start Time | <2s | Session ready state |
| WebSocket Event Latency | <10ms | Event delivery timing |

**Efficiency:**
| Metric | Target | Measurement |
|--------|--------|-------------|
| Agent Utilization | >70% | Active time / total time |
| Queue Wait Time (p95) | <30s | Time from enqueue to start |
| Resource Efficiency | >60% | Actual / provisioned capacity |

### 16.2 Business Metrics

**Adoption:**
- Daily Active Users (DAU)
- Tasks processed per day
- Sessions created per day

**Satisfaction:**
- Net Promoter Score (NPS)
- Support ticket volume
- Feature request volume

**Efficiency:**
- Developer time saved (vs. manual orchestration)
- Infrastructure cost per task
- Time to first successful deployment

---

## 17. Timeline & Milestones

### Phase 1: Foundation Hardening (COMPLETED)
**Duration:** 2 weeks  
**Status:** ‚úÖ Complete

**Deliverables:**
- [x] Queue correctness fixes
- [x] JWT hardening
- [x] API compatibility layer
- [x] Adapter robustness improvements
- [x] Integration test stabilization
- [x] Release gate implementation

**Validation:**
- `npm run verify:release` passing
- Unit test coverage >80%
- Zero critical security findings

### Phase 2: Federation Architecture (IN PROGRESS)
**Duration:** 3 weeks  
**Target:** 2026-02-28

**Deliverables:**
- [ ] Instance registry schema and API
- [ ] Health-aware routing implementation
- [ ] Session affinity policies
- [ ] Auto-scaling triggers
- [ ] Multi-tenant isolation (basic)

**Validation:**
- 10/25/50 session load tests passing
- <100ms routing overhead
- Zero cross-tenant data leakage

### Phase 3: Production Hardening (PLANNED)
**Duration:** 2 weeks  
**Target:** 2026-03-15

**Deliverables:**
- [ ] Comprehensive observability stack
- [ ] Production runbooks
- [ ] Disaster recovery automation
- [ ] Security audit and penetration testing
- [ ] Performance optimization

**Validation:**
- 99.9% uptime in staging soak test
- <30s MTTD, <5min MTTR
- SOC 2 readiness assessment

### Phase 4: General Availability (PLANNED)
**Duration:** 1 week  
**Target:** 2026-03-22

**Deliverables:**
- [ ] Production deployment
- [ ] Documentation complete
- [ ] Support channels established
- [ ] On-call rotation active

**Validation:**
- Production traffic handling 50 sessions
- Customer acceptance sign-off
- Operational readiness review

---

## 18. Dependencies & Risks

### 18.1 External Dependencies

| Dependency | Version | Purpose | Risk |
|------------|---------|---------|------|
| Node.js | >=20 | Runtime | Low (LTS) |
| PostgreSQL | >=15 | Database | Low (mature) |
| Redis | >=7 | Queue/Cache | Low (mature) |
| OpenClaw | latest | Agent runtime | Medium (evolving) |
| Fastify | ^5.x | API framework | Low (stable) |

### 18.2 Risk Register

| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| OpenClaw protocol changes | Medium | High | Version abstraction layer, integration tests |
| Redis single point of failure | Medium | High | Redis Sentinel/Cluster, fallback to DB queue |
| Database performance degradation | Low | High | Connection pooling, query optimization, read replicas |
| Security vulnerability discovered | Low | Critical | Security scanning, rapid patch process, incident response |
| Team capacity constraints | Medium | Medium | Scope prioritization, parallel workstreams, automation |
| Third-party dependency vulnerability | Medium | High | Automated dependency scanning, rapid update process |

---

## 19. Open Questions

### 19.1 Technical Decisions Pending

1. **Express or Fastify as Sole Production Server?**
   - Context: Both implementations exist, maintenance overhead
   - Options: (a) Deprecate Express, (b) Maintain both, (c) Gradual migration
   - Recommendation: Deprecate Express, focus on Fastify
   - Decision Owner: @tech-lead
   - Due Date: 2026-02-15

2. **OpenClaw Launch Mechanism?**
   - Context: `openclaw gateway` vs `openclawd` binary naming
   - Options: (a) Standardize on `openclaw gateway`, (b) Support both with detection
   - Recommendation: Support both with configurable override
   - Decision Owner: @platform-team
   - Due Date: 2026-02-10

3. **SLO Targets for GA?**
   - Context: Need explicit latency, error budget, failover time commitments
   - Options: Relaxed (99.5%) vs Standard (99.9%) vs Strict (99.99%)
   - Recommendation: 99.9% for GA, 99.99% as stretch
   - Decision Owner: @product-owner
   - Due Date: 2026-02-20

4. **Multi-Tenant Isolation Strategy?**
   - Context: 50+ instance pools with tenant separation requirements
   - Options: (a) Hard partition (instances per tenant), (b) Weighted shared pool
   - Recommendation: Weighted shared pool with resource quotas
   - Decision Owner: @architect
   - Due Date: 2026-02-28

### 19.2 Research Needed

1. **OpenClaw Gateway Federation Best Practices**
   - Official recommendations for multi-instance setups
   - Performance characteristics at scale
   - Resource requirements per instance

2. **Competitive Pricing Benchmarks**
   - Enterprise willingness to pay for orchestration
   - Pricing models for open-core vs managed service

3. **Compliance Requirements**
   - SOC 2 readiness assessment
   - GDPR implications for AI-generated code
   - Industry-specific requirements (finance, healthcare)

---

## 20. Appendices

### Appendix A: Glossary

| Term | Definition |
|------|------------|
| **Agent** | A Godel-managed entity that executes tasks via OpenClaw sessions |
| **Dead Letter Queue (DLQ)** | Storage for tasks that failed permanently after max retries |
| **Federation** | Management of multiple OpenClaw instances as a unified pool |
| **OpenClaw** | Gateway software that hosts AI agent sessions |
| **Session** | A connection between Godel and an OpenClaw gateway session |
| **Session Affinity** | Routing preference to keep related tasks on the same agent |
| **Team** | A group of related tasks or sessions working together |
| **Task** | A unit of work to be executed by an agent |

### Appendix B: Acronyms

| Acronym | Meaning |
|---------|---------|
| API | Application Programming Interface |
| DLQ | Dead Letter Queue |
| JWT | JSON Web Token |
| RBAC | Role-Based Access Control |
| RPO | Recovery Point Objective |
| RTO | Recovery Time Objective |
| SDK | Software Development Kit |
| SLA | Service Level Agreement |
| SLO | Service Level Objective |
| TLS | Transport Layer Security |
| WS | WebSocket |

### Appendix C: Related Documents

1. `specifications.md` - Detailed technical specifications
2. `docs/architecture/` - Architecture decision records
3. `docs/api/` - API documentation
4. `docs/runbooks/` - Operational runbooks
5. `config/examples/` - Configuration examples

### Appendix D: Revision History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2026-01-15 | @product-team | Initial PRD |
| 1.1 | 2026-01-30 | @engineering | Phase 1 updates |
| 2.0 | 2026-02-05 | @engineering | Comprehensive expansion |

---

## Validation Summary

This PRD has been systematically reviewed and expanded to serve as an exhaustive implementation blueprint. Key enhancements include:

1. ‚úÖ **Market Context & Competitive Positioning** - Complete competitive analysis with differentiators
2. ‚úÖ **Comprehensive User Stories** - 13 stories with technical implementation details
3. ‚úÖ **Detailed Requirements** - Functional, non-functional, and security requirements
4. ‚úÖ **Complete API Specifications** - OpenAPI 3.1 spec with all endpoints
5. ‚úÖ **Full Data Model** - Database schema and Redis data structures
6. ‚úÖ **Observability Strategy** - Metrics, logging, tracing, and alerting
7. ‚úÖ **Testing Strategy** - Test pyramid, categories, and release gates
8. ‚úÖ **Deployment & Operations** - Infrastructure, runbooks, and rollback procedures
9. ‚úÖ **Disaster Recovery** - Backup strategy and recovery procedures
10. ‚úÖ **Success Metrics** - Technical and business KPIs

**Ready for Implementation:** Engineering teams can proceed with full system implementation using this document as the authoritative specification.
